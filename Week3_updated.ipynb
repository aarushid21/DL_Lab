{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d508b892-da7f-47cf-98b1-64fb328024a4",
   "metadata": {
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1707153609806,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "d508b892-da7f-47cf-98b1-64fb328024a4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa045e4-1ab6-4c98-ad7f-38f4eeae6f4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 974,
     "status": "ok",
     "timestamp": 1707153612113,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "2fa045e4-1ab6-4c98-ad7f-38f4eeae6f4c",
    "outputId": "b2b8b6f9-0e57-48fd-a079-cbf6a2f8e063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0 W: 0.8889608383178711 B: 0.9937565326690674\n",
      "Epoch number: 1 W: 0.8468886017799377 B: 0.9913945198059082\n",
      "Epoch number: 2 W: 0.8309475183486938 B: 0.990503191947937\n",
      "Epoch number: 3 W: 0.8249073028564453 B: 0.990169107913971\n",
      "Epoch number: 4 W: 0.8226184844970703 B: 0.9900461435317993\n",
      "Epoch number: 5 W: 0.8217511177062988 B: 0.9900031685829163\n",
      "Epoch number: 6 W: 0.821422278881073 B: 0.9899904727935791\n",
      "Epoch number: 7 W: 0.8212974667549133 B: 0.9899892807006836\n",
      "Epoch number: 8 W: 0.8212499618530273 B: 0.9899924397468567\n",
      "Epoch number: 9 W: 0.8212317824363708 B: 0.9899972677230835\n",
      "Epoch number: 10 W: 0.8212246894836426 B: 0.9900026917457581\n",
      "Epoch number: 11 W: 0.8212217688560486 B: 0.9900083541870117\n",
      "Epoch number: 12 W: 0.8212204575538635 B: 0.9900141358375549\n",
      "Epoch number: 13 W: 0.8212197422981262 B: 0.9900199174880981\n",
      "Epoch number: 14 W: 0.821219265460968 B: 0.9900256991386414\n",
      "Epoch number: 15 W: 0.8212189078330994 B: 0.9900315403938293\n",
      "Epoch number: 16 W: 0.8212185502052307 B: 0.9900373816490173\n",
      "Epoch number: 17 W: 0.8212182521820068 B: 0.9900432229042053\n",
      "Epoch number: 18 W: 0.8212178945541382 B: 0.9900490641593933\n",
      "Epoch number: 19 W: 0.8212175965309143 B: 0.9900549054145813\n",
      "Epoch number: 20 W: 0.8212172389030457 B: 0.9900607466697693\n",
      "Epoch number: 21 W: 0.8212169408798218 B: 0.9900665879249573\n",
      "Epoch number: 22 W: 0.8212165832519531 B: 0.9900724291801453\n",
      "Epoch number: 23 W: 0.8212162852287292 B: 0.9900782704353333\n",
      "Epoch number: 24 W: 0.8212159276008606 B: 0.9900841116905212\n",
      "Epoch number: 25 W: 0.8212156295776367 B: 0.9900899529457092\n",
      "Epoch number: 26 W: 0.8212152719497681 B: 0.9900957345962524\n",
      "Epoch number: 27 W: 0.8212149739265442 B: 0.9901015758514404\n",
      "Epoch number: 28 W: 0.8212146162986755 B: 0.9901073575019836\n",
      "Epoch number: 29 W: 0.8212143182754517 B: 0.9901131987571716\n",
      "Epoch number: 30 W: 0.821213960647583 B: 0.9901189804077148\n",
      "Epoch number: 31 W: 0.8212136626243591 B: 0.9901248216629028\n",
      "Epoch number: 32 W: 0.8212133049964905 B: 0.990130603313446\n",
      "Epoch number: 33 W: 0.8212130069732666 B: 0.9901363849639893\n",
      "Epoch number: 34 W: 0.821212649345398 B: 0.9901421666145325\n",
      "Epoch number: 35 W: 0.8212123513221741 B: 0.9901479482650757\n",
      "Epoch number: 36 W: 0.8212120532989502 B: 0.9901537299156189\n",
      "Epoch number: 37 W: 0.8212116956710815 B: 0.9901595115661621\n",
      "Epoch number: 38 W: 0.8212113976478577 B: 0.9901652932167053\n",
      "Epoch number: 39 W: 0.821211040019989 B: 0.9901710748672485\n",
      "Epoch number: 40 W: 0.8212106823921204 B: 0.9901768565177917\n",
      "Epoch number: 41 W: 0.8212103843688965 B: 0.990182638168335\n",
      "Epoch number: 42 W: 0.8212100863456726 B: 0.9901884198188782\n",
      "Epoch number: 43 W: 0.821209728717804 B: 0.9901942014694214\n",
      "Epoch number: 44 W: 0.8212094306945801 B: 0.9901999831199646\n",
      "Epoch number: 45 W: 0.8212091326713562 B: 0.9902057647705078\n",
      "Epoch number: 46 W: 0.8212087750434875 B: 0.990211546421051\n",
      "Epoch number: 47 W: 0.8212084770202637 B: 0.9902173280715942\n",
      "Epoch number: 48 W: 0.821208119392395 B: 0.9902231097221375\n",
      "Epoch number: 49 W: 0.8212078213691711 B: 0.9902288913726807\n"
     ]
    }
   ],
   "source": [
    "#for the following trainng data, build a linear regression model, assume w and b are initialized with 1 and learning parameters are set to 0.01\n",
    "x = torch.tensor([11.4, 14.3, 14.5, 14.9, 16.1, 16.9, 16.5, 15.4, 17.0, 17.9, 18.8, 20.3, 22.4, 19.4, 15.5, 16.7, 17.3, 18.4, 19.2, 17.4, 19.5, 19.7, 21.2])\n",
    "y = torch.tensor([11.2, 12.5, 12.7, 13.1, 14.1, 14.8, 14.4, 13.4, 14.9, 15.6, 16.4, 17.7, 19.6, 16.9, 14.0, 14.6, 15.1, 16.1, 16.8, 15.2, 17.0, 17.2, 18.6])\n",
    "losses = []\n",
    "learning_rate = torch.tensor(0.001)\n",
    "w = torch.tensor([1.0], requires_grad = True)\n",
    "b = torch.tensor([1.0], requires_grad = True)\n",
    "for epoch in range(0, 50):\n",
    "    loss = 0.0\n",
    "    for data in range(0, len(x)):\n",
    "        a = w*x[data]\n",
    "        y_out = a + b\n",
    "        loss += (y_out - y[data])**2\n",
    "    loss = loss/len(x)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "        b -= learning_rate*b.grad\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    print(\"Epoch number: \" + str(epoch) + \" W: \" + str(w.item()) + \" B: \" + str(b.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6936ae14-be06-431f-a40f-0a0328e7ba5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1707153616182,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "6936ae14-be06-431f-a40f-0a0328e7ba5c",
    "outputId": "93064952-fe85-46c8-cad3-5332cbc044aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(1, len(losses) + 1)], losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486099bb-7228-410f-9158-1f6ee41cb5ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707153616886,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "486099bb-7228-410f-9158-1f6ee41cb5ce",
    "outputId": "1bc1d149-a9bb-4539-ad1f-77061df620b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0 W: 1.3480000495910645 B: 1.1039999723434448\n",
      "Epoch number: 1 W: 1.680832028388977 B: 1.2034080028533936\n"
     ]
    }
   ],
   "source": [
    "#Find the value of w.grad and b.grad using analytical solution for the given linear regressio proble,. INitial values of w = b = 1, learning parameter is set t0 0.001. Implement for two epochs\n",
    "x = torch.tensor([2, 4])\n",
    "y = torch.tensor([20, 40])\n",
    "w = torch.tensor([1.0], requires_grad = True)\n",
    "b = torch.tensor([1.0], requires_grad = True)\n",
    "learning_rate = 0.001\n",
    "for epochs in range(0, 2):\n",
    "    loss = 0.0\n",
    "    for data in range(0, len(x)):\n",
    "        y_out = w*x[data] + b\n",
    "        loss += (y_out - y[data])**2\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "        b -= learning_rate*b.grad\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    print(\"Epoch number: \" + str(epochs) + \" W: \" + str(w.item()) + \" B: \" + str(b.item()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45dada79-001d-4e76-accf-de08606d7799",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707153619590,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "45dada79-001d-4e76-accf-de08606d7799"
   },
   "outputs": [],
   "source": [
    "#Define a user defined class titled RegressionModel with parameters w and b. Define a constuctor to initialize w and b with values 1 and four functions (forward,update, reset grad and criterion), define an object of the class called model and invoke all methods\n",
    "\n",
    "class RegressionModel:\n",
    "    def __init__(self):\n",
    "        self.w = torch.tensor([1.0], requires_grad = True)\n",
    "        self.b = torch.tensor([1.0], requires_grad = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w*x + self.b\n",
    "\n",
    "    def update(self, learnng_rate):\n",
    "        self.w -= learning_rate*self.w.grad\n",
    "        self.b -= learning_rate*self.b.grad\n",
    "\n",
    "    def reset_grad(self):\n",
    "        self.w.grad.zero_()\n",
    "        self.w.grad.zero_()\n",
    "\n",
    "    def criterion(self, y, y_pred):\n",
    "        return (y - y_pred)**2\n",
    "\n",
    "    def display(self, epoch):\n",
    "        print(\"Epoch number: \" + str(epoch) + \" W: \" + str(self.w.item()) + \" B: \" + str(self.b.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617ecb4c-e336-451a-89ea-c7bcc4ebdd58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "executionInfo": {
     "elapsed": 2512,
     "status": "error",
     "timestamp": 1707153625170,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "617ecb4c-e336-451a-89ea-c7bcc4ebdd58",
    "outputId": "d1da8dfc-f221-44b2-f7eb-541607e7ffa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 loss value is: tensor(28064.0059, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(97110.1484, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(184393.9062, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(800012.1875, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(5438037., grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(16692784., grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(73247632., grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(3.8261e+08, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(1.6121e+09, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(2.7743e+09, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(8.7931e+09, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(3.5851e+10, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(1.3205e+11, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(4.4760e+11, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(2.1432e+12, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(6.4097e+12, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(7.9606e+12, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(5.2462e+11, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(2.3397e+13, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(1.5888e+14, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(5.2934e+14, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(1.1511e+15, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(7.0775e+15, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(4.2378e+16, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(2.5760e+17, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(1.3732e+18, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(4.3156e+18, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(1.8906e+19, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(4.4949e+19, grad_fn=<MseLossBackward0>)\n",
      "Epoch number: 1 loss value is: tensor(1.3213e+20, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Convert the program in Q3 to extend nn.module in your model, also override necessary methods to fit the regression line. Illustrate the use of dataset and dalaloader from torch.utils.data in your implementation, use SGD Optimizer torch.optim.SGD()\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class m1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.linear1 = nn.Linear(5, 5)\n",
    "    self.loss_fn = nn.MSELoss(reduction='mean')\n",
    "    self.op = optim.SGD(self.parameters(), lr = 0.01)\n",
    "\n",
    "  def forward(self, x):\n",
    "      y =self.linear1(x)\n",
    "      return y\n",
    "\n",
    "class xy_data(Dataset):\n",
    "  def __init__(self, x, y):\n",
    "    self.x = torch.tensor(x)\n",
    "    self.y = torch.tensor(y)\n",
    "\n",
    "  def size(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def get_item(self, index):\n",
    "    return [self.x[index], self.y[index]]\n",
    "\n",
    "\n",
    "data = xy_data([5.0, 7.0, 12.0, 16.0, 20.0], [40.0, 120.0, 180.0, 210.0, 240.0])\n",
    "loader = DataLoader(list(zip(data.x, data.y)), shuffle = True, batch_size = 5)\n",
    "n_epochs = 30\n",
    "losses = []\n",
    "model = m1()\n",
    "for epoch in range(n_epochs):\n",
    "  for x_batch, y_batch in loader:\n",
    "    y_pred = model.forward(x_batch)\n",
    "    loss = model.loss_fn(y_pred, y_batch)\n",
    "    losses.append(loss.item())\n",
    "    print(\"Epoch number: \" + str(epochs) + \" loss value is: \" + str(loss))\n",
    "    model.op.zero_grad()\n",
    "    loss.backward()\n",
    "    model.op.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "242605c6-7d8b-47e5-b162-7a435040f3a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1707153630415,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "242605c6-7d8b-47e5-b162-7a435040f3a8",
    "outputId": "114c3195-5e83-43b6-a79d-4800da3765ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25359.8008], grad_fn=<DivBackward0>)\n",
      "Epoch number: 0 W: 5.170400619506836 B: 1.2899999618530273\n",
      "tensor([10952.7344], grad_fn=<DivBackward0>)\n",
      "Epoch number: 1 W: 7.875868797302246 B: 1.769330382347107\n",
      "tensor([4853.2378], grad_fn=<DivBackward0>)\n",
      "Epoch number: 2 W: 9.624000549316406 B: 2.372101306915283\n",
      "tensor([2282.7014], grad_fn=<DivBackward0>)\n",
      "Epoch number: 3 W: 10.746519088745117 B: 3.05515193939209\n",
      "tensor([1206.9427], grad_fn=<DivBackward0>)\n",
      "Epoch number: 4 W: 11.460212707519531 B: 3.7901759147644043\n",
      "tensor([761.5485], grad_fn=<DivBackward0>)\n",
      "Epoch number: 5 W: 11.906758308410645 B: 4.558574199676514\n",
      "tensor([580.1817], grad_fn=<DivBackward0>)\n",
      "Epoch number: 6 W: 12.178750038146973 B: 5.348093509674072\n",
      "tensor([508.2358], grad_fn=<DivBackward0>)\n",
      "Epoch number: 7 W: 12.33670425415039 B: 6.150626182556152\n",
      "tensor([480.8898], grad_fn=<DivBackward0>)\n",
      "Epoch number: 8 W: 12.420177459716797 B: 6.9607768058776855\n",
      "tensor([471.2479], grad_fn=<DivBackward0>)\n",
      "Epoch number: 9 W: 12.455024719238281 B: 7.774921894073486\n",
      "tensor([468.3378], grad_fn=<DivBackward0>)\n",
      "Epoch number: 10 W: 12.458149909973145 B: 8.590596199035645\n",
      "tensor([467.8085], grad_fn=<DivBackward0>)\n",
      "Epoch number: 11 W: 12.440606117248535 B: 9.40609359741211\n",
      "tensor([468.0201], grad_fn=<DivBackward0>)\n",
      "Epoch number: 12 W: 12.409624099731445 B: 10.22020435333252\n",
      "tensor([468.4146], grad_fn=<DivBackward0>)\n",
      "Epoch number: 13 W: 12.369935035705566 B: 11.032044410705566\n",
      "tensor([468.8445], grad_fn=<DivBackward0>)\n",
      "Epoch number: 14 W: 12.324636459350586 B: 11.840941429138184\n",
      "tensor([469.3065], grad_fn=<DivBackward0>)\n",
      "Epoch number: 15 W: 12.275760650634766 B: 12.64636516571045\n",
      "tensor([469.8365], grad_fn=<DivBackward0>)\n",
      "Epoch number: 16 W: 12.224641799926758 B: 13.447877883911133\n",
      "tensor([470.4736], grad_fn=<DivBackward0>)\n",
      "Epoch number: 17 W: 12.172158241271973 B: 14.24510383605957\n",
      "tensor([471.2499], grad_fn=<DivBackward0>)\n",
      "Epoch number: 18 W: 12.118888854980469 B: 15.037707328796387\n",
      "tensor([472.1868], grad_fn=<DivBackward0>)\n",
      "Epoch number: 19 W: 12.06521987915039 B: 15.825382232666016\n",
      "tensor([473.2980], grad_fn=<DivBackward0>)\n",
      "Epoch number: 20 W: 12.011409759521484 B: 16.60784149169922\n",
      "tensor([474.5916], grad_fn=<DivBackward0>)\n",
      "Epoch number: 21 W: 11.957633018493652 B: 17.384811401367188\n",
      "tensor([476.0714], grad_fn=<DivBackward0>)\n",
      "Epoch number: 22 W: 11.904008865356445 B: 18.156028747558594\n",
      "tensor([477.7371], grad_fn=<DivBackward0>)\n",
      "Epoch number: 23 W: 11.850622177124023 B: 18.92123794555664\n",
      "tensor([479.5882], grad_fn=<DivBackward0>)\n",
      "Epoch number: 24 W: 11.797534942626953 B: 19.68018913269043\n",
      "tensor([481.6205], grad_fn=<DivBackward0>)\n",
      "Epoch number: 25 W: 11.744791984558105 B: 20.43263816833496\n",
      "tensor([483.8307], grad_fn=<DivBackward0>)\n",
      "Epoch number: 26 W: 11.692429542541504 B: 21.178348541259766\n",
      "tensor([486.2132], grad_fn=<DivBackward0>)\n",
      "Epoch number: 27 W: 11.64047622680664 B: 21.917083740234375\n",
      "tensor([488.7631], grad_fn=<DivBackward0>)\n",
      "Epoch number: 28 W: 11.588955879211426 B: 22.64861297607422\n",
      "tensor([491.4745], grad_fn=<DivBackward0>)\n",
      "Epoch number: 29 W: 11.537890434265137 B: 23.372709274291992\n",
      "tensor([494.3412], grad_fn=<DivBackward0>)\n",
      "Epoch number: 30 W: 11.487298965454102 B: 24.08915138244629\n",
      "tensor([497.3565], grad_fn=<DivBackward0>)\n",
      "Epoch number: 31 W: 11.437199592590332 B: 24.797719955444336\n",
      "tensor([500.5145], grad_fn=<DivBackward0>)\n",
      "Epoch number: 32 W: 11.387609481811523 B: 25.498199462890625\n",
      "tensor([503.8079], grad_fn=<DivBackward0>)\n",
      "Epoch number: 33 W: 11.338544845581055 B: 26.190380096435547\n",
      "tensor([507.2297], grad_fn=<DivBackward0>)\n",
      "Epoch number: 34 W: 11.290019989013672 B: 26.874055862426758\n",
      "tensor([510.7731], grad_fn=<DivBackward0>)\n",
      "Epoch number: 35 W: 11.24205207824707 B: 27.549022674560547\n",
      "tensor([514.4306], grad_fn=<DivBackward0>)\n",
      "Epoch number: 36 W: 11.19465446472168 B: 28.2150821685791\n",
      "tensor([518.1959], grad_fn=<DivBackward0>)\n",
      "Epoch number: 37 W: 11.147841453552246 B: 28.872039794921875\n",
      "tensor([522.0605], grad_fn=<DivBackward0>)\n",
      "Epoch number: 38 W: 11.101627349853516 B: 29.519704818725586\n",
      "tensor([526.0173], grad_fn=<DivBackward0>)\n",
      "Epoch number: 39 W: 11.056025505065918 B: 30.15789222717285\n",
      "tensor([530.0592], grad_fn=<DivBackward0>)\n",
      "Epoch number: 40 W: 11.011049270629883 B: 30.786418914794922\n",
      "tensor([534.1781], grad_fn=<DivBackward0>)\n",
      "Epoch number: 41 W: 10.96671199798584 B: 31.405107498168945\n",
      "tensor([538.3674], grad_fn=<DivBackward0>)\n",
      "Epoch number: 42 W: 10.923027038574219 B: 32.01378631591797\n",
      "tensor([542.6185], grad_fn=<DivBackward0>)\n",
      "Epoch number: 43 W: 10.880005836486816 B: 32.612281799316406\n",
      "tensor([546.9243], grad_fn=<DivBackward0>)\n",
      "Epoch number: 44 W: 10.837660789489746 B: 33.200435638427734\n",
      "tensor([551.2772], grad_fn=<DivBackward0>)\n",
      "Epoch number: 45 W: 10.796004295349121 B: 33.77808380126953\n",
      "tensor([555.6693], grad_fn=<DivBackward0>)\n",
      "Epoch number: 46 W: 10.755046844482422 B: 34.345069885253906\n",
      "tensor([560.0934], grad_fn=<DivBackward0>)\n",
      "Epoch number: 47 W: 10.714800834655762 B: 34.9012451171875\n",
      "tensor([564.5419], grad_fn=<DivBackward0>)\n",
      "Epoch number: 48 W: 10.675276756286621 B: 35.44646453857422\n",
      "tensor([569.0072], grad_fn=<DivBackward0>)\n",
      "Epoch number: 49 W: 10.63648509979248 B: 35.98058319091797\n",
      "tensor([573.4821], grad_fn=<DivBackward0>)\n",
      "Epoch number: 50 W: 10.598435401916504 B: 36.50346374511719\n",
      "tensor([577.9586], grad_fn=<DivBackward0>)\n",
      "Epoch number: 51 W: 10.561139106750488 B: 37.014976501464844\n",
      "tensor([582.4302], grad_fn=<DivBackward0>)\n",
      "Epoch number: 52 W: 10.524605751037598 B: 37.514991760253906\n",
      "tensor([586.8890], grad_fn=<DivBackward0>)\n",
      "Epoch number: 53 W: 10.48884391784668 B: 38.003387451171875\n",
      "tensor([591.3288], grad_fn=<DivBackward0>)\n",
      "Epoch number: 54 W: 10.453863143920898 B: 38.48004150390625\n",
      "tensor([595.7415], grad_fn=<DivBackward0>)\n",
      "Epoch number: 55 W: 10.419672012329102 B: 38.94484329223633\n",
      "tensor([600.1203], grad_fn=<DivBackward0>)\n",
      "Epoch number: 56 W: 10.38627815246582 B: 39.39768600463867\n",
      "tensor([604.4591], grad_fn=<DivBackward0>)\n",
      "Epoch number: 57 W: 10.353691101074219 B: 39.83845901489258\n",
      "tensor([608.7510], grad_fn=<DivBackward0>)\n",
      "Epoch number: 58 W: 10.321917533874512 B: 40.267066955566406\n",
      "tensor([612.9890], grad_fn=<DivBackward0>)\n",
      "Epoch number: 59 W: 10.290966033935547 B: 40.683414459228516\n",
      "tensor([617.1669], grad_fn=<DivBackward0>)\n",
      "Epoch number: 60 W: 10.260842323303223 B: 41.0874137878418\n",
      "tensor([621.2786], grad_fn=<DivBackward0>)\n",
      "Epoch number: 61 W: 10.23155403137207 B: 41.47897720336914\n",
      "tensor([625.3180], grad_fn=<DivBackward0>)\n",
      "Epoch number: 62 W: 10.203107833862305 B: 41.85802459716797\n",
      "tensor([629.2791], grad_fn=<DivBackward0>)\n",
      "Epoch number: 63 W: 10.175508499145508 B: 42.224483489990234\n",
      "tensor([633.1558], grad_fn=<DivBackward0>)\n",
      "Epoch number: 64 W: 10.148762702941895 B: 42.57828140258789\n",
      "tensor([636.9432], grad_fn=<DivBackward0>)\n",
      "Epoch number: 65 W: 10.122876167297363 B: 42.919349670410156\n",
      "tensor([640.6353], grad_fn=<DivBackward0>)\n",
      "Epoch number: 66 W: 10.097854614257812 B: 43.24763107299805\n",
      "tensor([644.2274], grad_fn=<DivBackward0>)\n",
      "Epoch number: 67 W: 10.073701858520508 B: 43.56306838989258\n",
      "tensor([647.7140], grad_fn=<DivBackward0>)\n",
      "Epoch number: 68 W: 10.050421714782715 B: 43.8656120300293\n",
      "tensor([651.0906], grad_fn=<DivBackward0>)\n",
      "Epoch number: 69 W: 10.028019905090332 B: 44.155216217041016\n",
      "tensor([654.3525], grad_fn=<DivBackward0>)\n",
      "Epoch number: 70 W: 10.006499290466309 B: 44.43183517456055\n",
      "tensor([657.4953], grad_fn=<DivBackward0>)\n",
      "Epoch number: 71 W: 9.985862731933594 B: 44.6954345703125\n",
      "tensor([660.5147], grad_fn=<DivBackward0>)\n",
      "Epoch number: 72 W: 9.96611499786377 B: 44.94598388671875\n",
      "tensor([663.4069], grad_fn=<DivBackward0>)\n",
      "Epoch number: 73 W: 9.947257995605469 B: 45.18345260620117\n",
      "tensor([666.1681], grad_fn=<DivBackward0>)\n",
      "Epoch number: 74 W: 9.929293632507324 B: 45.40782165527344\n",
      "tensor([668.7951], grad_fn=<DivBackward0>)\n",
      "Epoch number: 75 W: 9.912224769592285 B: 45.61907196044922\n",
      "tensor([671.2840], grad_fn=<DivBackward0>)\n",
      "Epoch number: 76 W: 9.896053314208984 B: 45.81718826293945\n",
      "tensor([673.6323], grad_fn=<DivBackward0>)\n",
      "Epoch number: 77 W: 9.880780220031738 B: 46.002166748046875\n",
      "tensor([675.8365], grad_fn=<DivBackward0>)\n",
      "Epoch number: 78 W: 9.86640739440918 B: 46.17400360107422\n",
      "tensor([677.8949], grad_fn=<DivBackward0>)\n",
      "Epoch number: 79 W: 9.852934837341309 B: 46.332698822021484\n",
      "tensor([679.8046], grad_fn=<DivBackward0>)\n",
      "Epoch number: 80 W: 9.840363502502441 B: 46.47825622558594\n",
      "tensor([681.5634], grad_fn=<DivBackward0>)\n",
      "Epoch number: 81 W: 9.828694343566895 B: 46.610687255859375\n",
      "tensor([683.1697], grad_fn=<DivBackward0>)\n",
      "Epoch number: 82 W: 9.817926406860352 B: 46.730010986328125\n",
      "tensor([684.6216], grad_fn=<DivBackward0>)\n",
      "Epoch number: 83 W: 9.808058738708496 B: 46.83624267578125\n",
      "tensor([685.9183], grad_fn=<DivBackward0>)\n",
      "Epoch number: 84 W: 9.799091339111328 B: 46.92940902709961\n",
      "tensor([687.0576], grad_fn=<DivBackward0>)\n",
      "Epoch number: 85 W: 9.791023254394531 B: 47.00953674316406\n",
      "tensor([688.0394], grad_fn=<DivBackward0>)\n",
      "Epoch number: 86 W: 9.783852577209473 B: 47.076663970947266\n",
      "tensor([688.8629], grad_fn=<DivBackward0>)\n",
      "Epoch number: 87 W: 9.77757740020752 B: 47.13082504272461\n",
      "tensor([689.5272], grad_fn=<DivBackward0>)\n",
      "Epoch number: 88 W: 9.772196769714355 B: 47.172061920166016\n",
      "tensor([690.0330], grad_fn=<DivBackward0>)\n",
      "Epoch number: 89 W: 9.767706871032715 B: 47.20042037963867\n",
      "tensor([690.3792], grad_fn=<DivBackward0>)\n",
      "Epoch number: 90 W: 9.764106750488281 B: 47.2159538269043\n",
      "tensor([690.5665], grad_fn=<DivBackward0>)\n",
      "Epoch number: 91 W: 9.761391639709473 B: 47.21871566772461\n",
      "tensor([690.5955], grad_fn=<DivBackward0>)\n",
      "Epoch number: 92 W: 9.759559631347656 B: 47.20876693725586\n",
      "tensor([690.4668], grad_fn=<DivBackward0>)\n",
      "Epoch number: 93 W: 9.758606910705566 B: 47.18617248535156\n",
      "tensor([690.1813], grad_fn=<DivBackward0>)\n",
      "Epoch number: 94 W: 9.758529663085938 B: 47.150997161865234\n",
      "tensor([689.7404], grad_fn=<DivBackward0>)\n",
      "Epoch number: 95 W: 9.759324073791504 B: 47.10331726074219\n",
      "tensor([689.1447], grad_fn=<DivBackward0>)\n",
      "Epoch number: 96 W: 9.760984420776367 B: 47.04320526123047\n",
      "tensor([688.3965], grad_fn=<DivBackward0>)\n",
      "Epoch number: 97 W: 9.763506889343262 B: 46.97074508666992\n",
      "tensor([687.4974], grad_fn=<DivBackward0>)\n",
      "Epoch number: 98 W: 9.766886711120605 B: 46.88602066040039\n",
      "tensor([686.4491], grad_fn=<DivBackward0>)\n",
      "Epoch number: 99 W: 9.771119117736816 B: 46.78911590576172\n"
     ]
    }
   ],
   "source": [
    "model = RegressionModel()\n",
    "x = torch.tensor([5.0, 7.0, 12.0, 16.0, 20.0])\n",
    "y = torch.tensor([40.0, 120.0, 180.0, 210.0, 240.0])\n",
    "losses = []\n",
    "for epoch in range(0, 100):\n",
    "    loss = 0.0\n",
    "    for data in range(0, len(x)):\n",
    "        y_out = model.forward(x[data])\n",
    "        loss += model.criterion(y_out, y[data])\n",
    "    loss = loss/len(x)\n",
    "    print(loss)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        model.update(0.01)\n",
    "    model.reset_grad()\n",
    "    model.display(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e3957-ff51-4d5c-934a-a2e16b041bf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1706098943557,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "143e3957-ff51-4d5c-934a-a2e16b041bf1",
    "outputId": "f40f1050-9989-4274-edd5-85803e566eec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(1, len(losses) + 1)], losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9130b9f3-6341-45c4-b70c-981fa3e5c1cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "executionInfo": {
     "elapsed": 560,
     "status": "error",
     "timestamp": 1707153650448,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "9130b9f3-6341-45c4-b70c-981fa3e5c1cb",
    "outputId": "e73f15d4-e73e-4ab0-b60d-c7f8c911b0ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(29598.2383, grad_fn=<MseLossBackward0>)\n",
      "tensor(117107.6719, grad_fn=<MseLossBackward0>)\n",
      "tensor(593827.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1863169., grad_fn=<MseLossBackward0>)\n",
      "tensor(9198774., grad_fn=<MseLossBackward0>)\n",
      "tensor(48479656., grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4133e+08, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7529e+08, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7205e+09, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.6199e+09, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.7229e+10, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.3616e+10, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1158e+11, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2627e+12, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9994e+12, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.8252e+12, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7187e+13, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.8449e+14, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0236e+15, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5671e+15, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0333e+16, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2325e+16, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7956e+17, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5601e+18, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.5782e+18, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3427e+19, grad_fn=<MseLossBackward0>)\n",
      "tensor(1.1360e+20, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0711e+20, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6577e+20, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5989e+21, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Use PyTorch's nn.Linear() in your implementation to perform linear regression for the data in Q1, plot the graph\n",
    "x = torch.tensor([11.4, 14.3, 14.5, 14.9, 16.1, 16.9, 16.5, 15.4, 17.0, 17.9, 18.8, 20.3, 22.4, 19.4, 15.5, 16.7, 17.3, 18.4, 19.2, 17.4, 19.5, 19.7, 21.2])\n",
    "y = torch.tensor([11.2, 12.5, 12.7, 13.1, 14.1, 14.8, 14.4, 13.4, 14.9, 15.6, 16.4, 17.7, 19.6, 16.9, 14.0, 14.6, 15.1, 16.1, 16.8, 15.2, 17.0, 17.2, 18.6])\n",
    "data = xy_data([5.0, 7.0, 12.0, 16.0, 20.0], [40.0, 120.0, 180.0, 210.0, 240.0])\n",
    "loader = DataLoader(list(zip(data.x, data.y)), shuffle = True, batch_size = 5)\n",
    "n_epochs = 30\n",
    "losses = []\n",
    "model = m1()\n",
    "for epoch in range(n_epochs):\n",
    "  for x_batch, y_batch in loader:\n",
    "    y_pred = model.forward(x_batch)\n",
    "    loss = model.loss_fn(y_pred, y_batch)\n",
    "    print(loss)\n",
    "    losses.append(loss.item())\n",
    "    model.op.zero_grad()\n",
    "    loss.backward()\n",
    "    model.op.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3deb5e-9490-4eb1-892a-f4f66c05b96d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1706099651046,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "1e3deb5e-9490-4eb1-892a-f4f66c05b96d",
    "outputId": "78bb6555-5a72-47d6-dfa4-3d9eca358437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0 W1: 0.9377599954605103 W2: 0.9013599753379822 B: 0.9869199991226196\n",
      "Epoch number: 1 W1: 0.881771445274353 W2: 0.8111497163772583 B: 0.9753110408782959\n",
      "Epoch number: 2 W1: 0.831463634967804 W2: 0.7286084890365601 B: 0.9650391936302185\n",
      "Epoch number: 3 W1: 0.7863177061080933 W2: 0.6530445218086243 B: 0.9559827446937561\n",
      "Epoch number: 4 W1: 0.745861828327179 W2: 0.5838286876678467 B: 0.9480310082435608\n",
      "Epoch number: 5 W1: 0.7096669673919678 W2: 0.5203887820243835 B: 0.9410833120346069\n",
      "Epoch number: 6 W1: 0.6773428916931152 W2: 0.46220454573631287 B: 0.9350481033325195\n",
      "Epoch number: 7 W1: 0.6485348343849182 W2: 0.4088028073310852 B: 0.9298421144485474\n",
      "Epoch number: 8 W1: 0.6229202747344971 W2: 0.35975322127342224 B: 0.9253896474838257\n",
      "Epoch number: 9 W1: 0.6002057790756226 W2: 0.31466445326805115 B: 0.9216218590736389\n",
      "Epoch number: 10 W1: 0.5801246762275696 W2: 0.27318060398101807 B: 0.9184761643409729\n",
      "Epoch number: 11 W1: 0.5624344348907471 W2: 0.23497800529003143 B: 0.9158957004547119\n",
      "Epoch number: 12 W1: 0.5469145178794861 W2: 0.19976229965686798 B: 0.9138286709785461\n",
      "Epoch number: 13 W1: 0.5333643555641174 W2: 0.16726580262184143 B: 0.912227988243103\n",
      "Epoch number: 14 W1: 0.521601676940918 W2: 0.1372450441122055 B: 0.9110508561134338\n",
      "Epoch number: 15 W1: 0.5114607214927673 W2: 0.10947862267494202 B: 0.910258412361145\n",
      "Epoch number: 16 W1: 0.5027906894683838 W2: 0.08376516401767731 B: 0.9098151922225952\n",
      "Epoch number: 17 W1: 0.4954546093940735 W2: 0.05992152541875839 B: 0.9096890687942505\n",
      "Epoch number: 18 W1: 0.4893278479576111 W2: 0.03778115287423134 B: 0.9098508358001709\n",
      "Epoch number: 19 W1: 0.48429709672927856 W2: 0.017192557454109192 B: 0.9102737903594971\n",
      "Epoch number: 20 W1: 0.48025938868522644 W2: -0.001982038840651512 B: 0.910933792591095\n",
      "Epoch number: 21 W1: 0.4771210551261902 W2: -0.01986793987452984 B: 0.9118088483810425\n",
      "Epoch number: 22 W1: 0.47479701042175293 W2: -0.03657911717891693 B: 0.9128789901733398\n",
      "Epoch number: 23 W1: 0.47320982813835144 W2: -0.05221923440694809 B: 0.9141260385513306\n",
      "Epoch number: 24 W1: 0.47228914499282837 W2: -0.06688257306814194 B: 0.9155334234237671\n",
      "Epoch number: 25 W1: 0.4719710052013397 W2: -0.08065489679574966 B: 0.917086124420166\n",
      "Epoch number: 26 W1: 0.4721972942352295 W2: -0.09361420571804047 B: 0.9187704920768738\n",
      "Epoch number: 27 W1: 0.4729151427745819 W2: -0.10583145916461945 B: 0.9205740690231323\n",
      "Epoch number: 28 W1: 0.4740765392780304 W2: -0.11737118661403656 B: 0.9224855899810791\n",
      "Epoch number: 29 W1: 0.4756377935409546 W2: -0.12829209864139557 B: 0.924494743347168\n",
      "Epoch number: 30 W1: 0.47755923867225647 W2: -0.13864761590957642 B: 0.926592230796814\n",
      "Epoch number: 31 W1: 0.4798048138618469 W2: -0.14848630130290985 B: 0.928769588470459\n",
      "Epoch number: 32 W1: 0.4823417365550995 W2: -0.15785236656665802 B: 0.9310190677642822\n",
      "Epoch number: 33 W1: 0.48514023423194885 W2: -0.16678601503372192 B: 0.933333694934845\n",
      "Epoch number: 34 W1: 0.488173246383667 W2: -0.17532384395599365 B: 0.9357070326805115\n",
      "Epoch number: 35 W1: 0.49141618609428406 W2: -0.18349912762641907 B: 0.9381333589553833\n",
      "Epoch number: 36 W1: 0.4948467016220093 W2: -0.19134214520454407 B: 0.9406073689460754\n",
      "Epoch number: 37 W1: 0.49844449758529663 W2: -0.19888044893741608 B: 0.9431242942810059\n",
      "Epoch number: 38 W1: 0.5021911859512329 W2: -0.20613911747932434 B: 0.9456797242164612\n",
      "Epoch number: 39 W1: 0.5060699582099915 W2: -0.21314097940921783 B: 0.948269784450531\n",
      "Epoch number: 40 W1: 0.5100656747817993 W2: -0.2199067920446396 B: 0.950890839099884\n",
      "Epoch number: 41 W1: 0.5141645073890686 W2: -0.2264554649591446 B: 0.9535396099090576\n",
      "Epoch number: 42 W1: 0.5183538794517517 W2: -0.23280419409275055 B: 0.9562131762504578\n",
      "Epoch number: 43 W1: 0.5226224660873413 W2: -0.2389686405658722 B: 0.9589088559150696\n",
      "Epoch number: 44 W1: 0.5269599556922913 W2: -0.24496307969093323 B: 0.9616241455078125\n",
      "Epoch number: 45 W1: 0.531356930732727 W2: -0.2508004605770111 B: 0.9643568396568298\n",
      "Epoch number: 46 W1: 0.5358049273490906 W2: -0.25649264454841614 B: 0.967104971408844\n",
      "Epoch number: 47 W1: 0.540296196937561 W2: -0.2620503604412079 B: 0.9698666334152222\n",
      "Epoch number: 48 W1: 0.5448238253593445 W2: -0.2674834132194519 B: 0.9726402163505554\n",
      "Epoch number: 49 W1: 0.5493813753128052 W2: -0.2728007733821869 B: 0.9754241704940796\n",
      "Epoch number: 50 W1: 0.5539631843566895 W2: -0.2780105471611023 B: 0.9782171845436096\n",
      "Epoch number: 51 W1: 0.5585640072822571 W2: -0.28312015533447266 B: 0.9810179471969604\n",
      "Epoch number: 52 W1: 0.5631791353225708 W2: -0.28813636302948 B: 0.9838253259658813\n",
      "Epoch number: 53 W1: 0.5678042769432068 W2: -0.29306530952453613 B: 0.9866383671760559\n",
      "Epoch number: 54 W1: 0.5724356174468994 W2: -0.2979126274585724 B: 0.989456057548523\n",
      "Epoch number: 55 W1: 0.5770696401596069 W2: -0.30268344283103943 B: 0.9922776222229004\n",
      "Epoch number: 56 W1: 0.5817031860351562 W2: -0.30738240480422974 B: 0.9951022863388062\n",
      "Epoch number: 57 W1: 0.5863333940505981 W2: -0.31201380491256714 B: 0.9979293346405029\n",
      "Epoch number: 58 W1: 0.5909577012062073 W2: -0.31658151745796204 B: 1.000758171081543\n",
      "Epoch number: 59 W1: 0.5955737829208374 W2: -0.32108908891677856 B: 1.0035881996154785\n",
      "Epoch number: 60 W1: 0.6001795530319214 W2: -0.32553979754447937 B: 1.0064189434051514\n",
      "Epoch number: 61 W1: 0.6047731041908264 W2: -0.32993656396865845 B: 1.0092498064041138\n",
      "Epoch number: 62 W1: 0.6093527674674988 W2: -0.33428213000297546 B: 1.0120805501937866\n",
      "Epoch number: 63 W1: 0.6139169931411743 W2: -0.3385789692401886 B: 1.0149106979370117\n",
      "Epoch number: 64 W1: 0.6184644103050232 W2: -0.3428293466567993 B: 1.0177398920059204\n",
      "Epoch number: 65 W1: 0.6229938268661499 W2: -0.34703534841537476 B: 1.0205678939819336\n",
      "Epoch number: 66 W1: 0.6275041103363037 W2: -0.35119885206222534 B: 1.0233943462371826\n",
      "Epoch number: 67 W1: 0.6319943070411682 W2: -0.35532161593437195 B: 1.0262190103530884\n",
      "Epoch number: 68 W1: 0.6364635229110718 W2: -0.3594052493572235 B: 1.0290416479110718\n",
      "Epoch number: 69 W1: 0.6409109234809875 W2: -0.363451212644577 B: 1.0318621397018433\n",
      "Epoch number: 70 W1: 0.6453359127044678 W2: -0.36746084690093994 B: 1.0346802473068237\n",
      "Epoch number: 71 W1: 0.6497378349304199 W2: -0.37143540382385254 B: 1.0374958515167236\n",
      "Epoch number: 72 W1: 0.654116153717041 W2: -0.37537601590156555 B: 1.0403087139129639\n",
      "Epoch number: 73 W1: 0.6584703922271729 W2: -0.37928372621536255 B: 1.0431188344955444\n",
      "Epoch number: 74 W1: 0.662800133228302 W2: -0.38315948843955994 B: 1.0459259748458862\n",
      "Epoch number: 75 W1: 0.6671050190925598 W2: -0.38700422644615173 B: 1.0487300157546997\n",
      "Epoch number: 76 W1: 0.6713847517967224 W2: -0.3908187448978424 B: 1.0515309572219849\n",
      "Epoch number: 77 W1: 0.6756390929222107 W2: -0.39460381865501404 B: 1.0543286800384521\n",
      "Epoch number: 78 W1: 0.6798677444458008 W2: -0.39836013317108154 B: 1.057123064994812\n",
      "Epoch number: 79 W1: 0.6840705871582031 W2: -0.40208834409713745 B: 1.0599141120910645\n",
      "Epoch number: 80 W1: 0.6882474422454834 W2: -0.4057890772819519 B: 1.0627018213272095\n",
      "Epoch number: 81 W1: 0.692398190498352 W2: -0.40946289896965027 B: 1.065485954284668\n",
      "Epoch number: 82 W1: 0.6965227127075195 W2: -0.41311031579971313 B: 1.0682666301727295\n",
      "Epoch number: 83 W1: 0.7006209492683411 W2: -0.4167318344116211 B: 1.0710437297821045\n",
      "Epoch number: 84 W1: 0.7046928405761719 W2: -0.42032793164253235 B: 1.073817253112793\n",
      "Epoch number: 85 W1: 0.7087383270263672 W2: -0.42389899492263794 B: 1.076587200164795\n",
      "Epoch number: 86 W1: 0.7127574682235718 W2: -0.4274454414844513 B: 1.0793535709381104\n",
      "Epoch number: 87 W1: 0.7167502045631409 W2: -0.43096765875816345 B: 1.0821162462234497\n",
      "Epoch number: 88 W1: 0.7207165956497192 W2: -0.43446600437164307 B: 1.0848753452301025\n",
      "Epoch number: 89 W1: 0.7246566414833069 W2: -0.4379408061504364 B: 1.0876307487487793\n",
      "Epoch number: 90 W1: 0.7285704016685486 W2: -0.44139236211776733 B: 1.09038245677948\n",
      "Epoch number: 91 W1: 0.7324579358100891 W2: -0.44482100009918213 B: 1.0931304693222046\n",
      "Epoch number: 92 W1: 0.7363193035125732 W2: -0.4482269883155823 B: 1.0958747863769531\n",
      "Epoch number: 93 W1: 0.7401546239852905 W2: -0.45161059498786926 B: 1.0986154079437256\n",
      "Epoch number: 94 W1: 0.743963897228241 W2: -0.4549720883369446 B: 1.1013524532318115\n",
      "Epoch number: 95 W1: 0.7477473020553589 W2: -0.45831170678138733 B: 1.1040858030319214\n",
      "Epoch number: 96 W1: 0.7515048384666443 W2: -0.4616296589374542 B: 1.1068154573440552\n",
      "Epoch number: 97 W1: 0.7552366852760315 W2: -0.46492621302604675 B: 1.109541416168213\n",
      "Epoch number: 98 W1: 0.7589429020881653 W2: -0.46820154786109924 B: 1.1122636795043945\n",
      "Epoch number: 99 W1: 0.7626236081123352 W2: -0.4714559018611908 B: 1.1149823665618896\n"
     ]
    }
   ],
   "source": [
    "#Implement multiple linear regression for the given data\n",
    "x1 = torch.tensor([3, 4, 5, 6, 2])\n",
    "x2 = torch.tensor([8, 5, 7, 3, 1])\n",
    "y = torch.tensor([-3.7, 3.5, 2.5, 2.5, 11.5])\n",
    "losses = []\n",
    "learning_rate = torch.tensor(0.001)\n",
    "w1 = torch.tensor([1.0], requires_grad = True)\n",
    "w2 = torch.tensor([1.0], requires_grad = True)\n",
    "b = torch.tensor([1.0], requires_grad = True)\n",
    "\n",
    "for epoch in range(0, 100):\n",
    "    loss = 0.0\n",
    "    for data in range(0, len(x1)):\n",
    "        a = w1*x1[data] + w2*x2[data]\n",
    "        y_out = a + b\n",
    "        loss += (y_out - y[data])**2\n",
    "    loss = loss/len(x1)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate*w1.grad\n",
    "        w2 -= learning_rate*w2.grad\n",
    "        b -= learning_rate*b.grad\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    print(\"Epoch number: \" + str(epoch) + \" W1: \" + str(w1.item()) + \" W2: \" + str(w2.item()) + \" B: \" + str(b.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gtH8OVl1dtRm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1706099677226,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "gtH8OVl1dtRm",
    "outputId": "f4b794ca-6706-4331-86f8-c69b73a9af4f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(1, len(losses) + 1)], losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b2456-2d97-43a7-938d-a00963285588",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7338,
     "status": "ok",
     "timestamp": 1706064179842,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "c79b2456-2d97-43a7-938d-a00963285588",
    "outputId": "1cde072c-1562-41ee-a266-e937e0d1eb14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2324], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2225], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2125], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2026], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1926], grad_fn=<AddBackward0>)\n",
      "Epoch number: 21 W: 0.9954904913902283 B: 0.997517466545105\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8801], grad_fn=<MulBackward0>)\n",
      "tensor([2.0407], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9975], grad_fn=<MulBackward0>)\n",
      "tensor([6.4199], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0233], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6268], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2319], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2220], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2120], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2021], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1921], grad_fn=<AddBackward0>)\n",
      "Epoch number: 22 W: 0.9952842593193054 B: 0.9974043965339661\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8800], grad_fn=<MulBackward0>)\n",
      "tensor([2.0404], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9975], grad_fn=<MulBackward0>)\n",
      "tensor([6.4194], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0228], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6263], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2314], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2215], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2115], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2016], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1916], grad_fn=<AddBackward0>)\n",
      "Epoch number: 23 W: 0.995077908039093 B: 0.9972913265228271\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8800], grad_fn=<MulBackward0>)\n",
      "tensor([2.0402], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9975], grad_fn=<MulBackward0>)\n",
      "tensor([6.4189], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0223], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6257], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2309], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2210], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2110], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2011], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1911], grad_fn=<AddBackward0>)\n",
      "Epoch number: 24 W: 0.9948714971542358 B: 0.9971781969070435\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8800], grad_fn=<MulBackward0>)\n",
      "tensor([2.0399], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9975], grad_fn=<MulBackward0>)\n",
      "tensor([6.4184], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0218], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6252], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2304], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2205], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2105], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2006], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1906], grad_fn=<AddBackward0>)\n",
      "Epoch number: 25 W: 0.9946649670600891 B: 0.9970650672912598\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8799], grad_fn=<MulBackward0>)\n",
      "tensor([2.0397], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9975], grad_fn=<MulBackward0>)\n",
      "tensor([6.4179], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0214], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6248], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2299], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2200], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2100], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2001], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1901], grad_fn=<AddBackward0>)\n",
      "Epoch number: 26 W: 0.9944583177566528 B: 0.9969519376754761\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8799], grad_fn=<MulBackward0>)\n",
      "tensor([2.0394], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9975], grad_fn=<MulBackward0>)\n",
      "tensor([6.4175], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0208], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6242], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2294], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2195], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2095], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1996], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1896], grad_fn=<AddBackward0>)\n",
      "Epoch number: 27 W: 0.994251549243927 B: 0.9968387484550476\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8799], grad_fn=<MulBackward0>)\n",
      "tensor([2.0391], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4170], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0204], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6238], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2289], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2190], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2090], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1991], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1891], grad_fn=<AddBackward0>)\n",
      "Epoch number: 28 W: 0.9940446615219116 B: 0.9967255592346191\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8798], grad_fn=<MulBackward0>)\n",
      "tensor([2.0389], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4165], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0199], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6233], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2284], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2185], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2085], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1986], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1886], grad_fn=<AddBackward0>)\n",
      "Epoch number: 29 W: 0.9938376545906067 B: 0.9966123700141907\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8798], grad_fn=<MulBackward0>)\n",
      "tensor([2.0386], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4160], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0194], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6227], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2279], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2180], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2080], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1981], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1881], grad_fn=<AddBackward0>)\n",
      "Epoch number: 30 W: 0.993630588054657 B: 0.9964991211891174\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8798], grad_fn=<MulBackward0>)\n",
      "tensor([2.0384], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4155], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0189], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6223], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2274], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2175], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2075], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1976], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1876], grad_fn=<AddBackward0>)\n",
      "Epoch number: 31 W: 0.9934234023094177 B: 0.9963858723640442\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8797], grad_fn=<MulBackward0>)\n",
      "tensor([2.0381], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4150], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0184], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6218], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2269], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2170], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2070], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1971], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1871], grad_fn=<AddBackward0>)\n",
      "Epoch number: 32 W: 0.9932160973548889 B: 0.996272623538971\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8797], grad_fn=<MulBackward0>)\n",
      "tensor([2.0378], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4145], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0179], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6213], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2264], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2165], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2065], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1966], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1866], grad_fn=<AddBackward0>)\n",
      "Epoch number: 33 W: 0.9930086731910706 B: 0.9961593151092529\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8797], grad_fn=<MulBackward0>)\n",
      "tensor([2.0376], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4140], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0174], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6207], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2259], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2160], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2060], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1961], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1861], grad_fn=<AddBackward0>)\n",
      "Epoch number: 34 W: 0.9928011298179626 B: 0.9960460066795349\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8796], grad_fn=<MulBackward0>)\n",
      "tensor([2.0373], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4135], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0169], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6202], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2254], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2155], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2055], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1956], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1856], grad_fn=<AddBackward0>)\n",
      "Epoch number: 35 W: 0.9925934672355652 B: 0.9959326982498169\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8796], grad_fn=<MulBackward0>)\n",
      "tensor([2.0370], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4130], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0164], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6197], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2249], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2150], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2050], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1951], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1851], grad_fn=<AddBackward0>)\n",
      "Epoch number: 36 W: 0.992385745048523 B: 0.9958193302154541\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8796], grad_fn=<MulBackward0>)\n",
      "tensor([2.0368], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4125], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0159], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6192], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2244], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2144], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2045], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1945], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1846], grad_fn=<AddBackward0>)\n",
      "Epoch number: 37 W: 0.9921779036521912 B: 0.9957059621810913\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8795], grad_fn=<MulBackward0>)\n",
      "tensor([2.0365], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4120], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0154], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6187], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2239], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2139], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2040], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1940], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1841], grad_fn=<AddBackward0>)\n",
      "Epoch number: 38 W: 0.9919699430465698 B: 0.9955925941467285\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8795], grad_fn=<MulBackward0>)\n",
      "tensor([2.0363], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4115], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0149], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6182], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2234], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2134], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2035], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1935], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1836], grad_fn=<AddBackward0>)\n",
      "Epoch number: 39 W: 0.9917618632316589 B: 0.995479166507721\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8795], grad_fn=<MulBackward0>)\n",
      "tensor([2.0360], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4110], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0144], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6177], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2229], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2129], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2030], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1930], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1831], grad_fn=<AddBackward0>)\n",
      "Epoch number: 40 W: 0.9915536642074585 B: 0.9953657388687134\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8794], grad_fn=<MulBackward0>)\n",
      "tensor([2.0357], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4105], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0139], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6172], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2224], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2124], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2025], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1925], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1826], grad_fn=<AddBackward0>)\n",
      "Epoch number: 41 W: 0.9913453459739685 B: 0.9952523112297058\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8794], grad_fn=<MulBackward0>)\n",
      "tensor([2.0355], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4100], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0134], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6167], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2219], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2119], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2020], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1920], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1821], grad_fn=<AddBackward0>)\n",
      "Epoch number: 42 W: 0.991136908531189 B: 0.9951388239860535\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8793], grad_fn=<MulBackward0>)\n",
      "tensor([2.0352], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4095], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0129], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6162], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2214], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2114], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2015], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1915], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1816], grad_fn=<AddBackward0>)\n",
      "Epoch number: 43 W: 0.9909283518791199 B: 0.9950253367424011\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8793], grad_fn=<MulBackward0>)\n",
      "tensor([2.0350], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4090], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0124], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6157], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2209], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2109], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2010], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1910], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1811], grad_fn=<AddBackward0>)\n",
      "Epoch number: 44 W: 0.990719735622406 B: 0.9949118494987488\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8793], grad_fn=<MulBackward0>)\n",
      "tensor([2.0347], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4085], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0118], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6152], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2203], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2104], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2004], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1905], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1805], grad_fn=<AddBackward0>)\n",
      "Epoch number: 45 W: 0.9905110001564026 B: 0.9947983026504517\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8792], grad_fn=<MulBackward0>)\n",
      "tensor([2.0344], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4080], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0114], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6147], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2198], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2099], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1999], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1900], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1800], grad_fn=<AddBackward0>)\n",
      "Epoch number: 46 W: 0.9903021454811096 B: 0.9946847558021545\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8792], grad_fn=<MulBackward0>)\n",
      "tensor([2.0342], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4075], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0108], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6142], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2193], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2094], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1994], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1895], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1795], grad_fn=<AddBackward0>)\n",
      "Epoch number: 47 W: 0.9900931715965271 B: 0.9945712089538574\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8792], grad_fn=<MulBackward0>)\n",
      "tensor([2.0339], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4070], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0103], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6137], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2188], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2089], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1989], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1890], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1790], grad_fn=<AddBackward0>)\n",
      "Epoch number: 48 W: 0.989884078502655 B: 0.9944576025009155\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8791], grad_fn=<MulBackward0>)\n",
      "tensor([2.0337], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4065], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0098], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6131], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2183], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2084], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1984], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1885], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1785], grad_fn=<AddBackward0>)\n",
      "Epoch number: 49 W: 0.9896748661994934 B: 0.9943439960479736\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8791], grad_fn=<MulBackward0>)\n",
      "tensor([2.0334], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4060], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0093], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6126], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2178], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2079], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1979], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1880], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1780], grad_fn=<AddBackward0>)\n",
      "Epoch number: 50 W: 0.9894655346870422 B: 0.9942303895950317\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8791], grad_fn=<MulBackward0>)\n",
      "tensor([2.0331], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4055], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0088], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6121], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2173], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2073], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1974], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1874], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1775], grad_fn=<AddBackward0>)\n",
      "Epoch number: 51 W: 0.9892560839653015 B: 0.9941167235374451\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8790], grad_fn=<MulBackward0>)\n",
      "tensor([2.0329], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4050], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0083], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6116], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2168], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2068], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1969], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1869], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1770], grad_fn=<AddBackward0>)\n",
      "Epoch number: 52 W: 0.989046573638916 B: 0.9940030574798584\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8790], grad_fn=<MulBackward0>)\n",
      "tensor([2.0326], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4045], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0078], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6111], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2163], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2063], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1964], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1864], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1765], grad_fn=<AddBackward0>)\n",
      "Epoch number: 53 W: 0.988836944103241 B: 0.9938893914222717\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8790], grad_fn=<MulBackward0>)\n",
      "tensor([2.0323], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4040], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0073], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6106], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2157], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2058], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1958], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1859], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1759], grad_fn=<AddBackward0>)\n",
      "Epoch number: 54 W: 0.9886271953582764 B: 0.9937756657600403\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8789], grad_fn=<MulBackward0>)\n",
      "tensor([2.0321], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4035], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0068], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6101], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2153], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2053], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1954], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1854], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1755], grad_fn=<AddBackward0>)\n",
      "Epoch number: 55 W: 0.9884173274040222 B: 0.9936619400978088\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8789], grad_fn=<MulBackward0>)\n",
      "tensor([2.0318], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4030], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0063], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6096], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2147], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2048], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1948], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1849], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1749], grad_fn=<AddBackward0>)\n",
      "Epoch number: 56 W: 0.9882073402404785 B: 0.9935482144355774\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8789], grad_fn=<MulBackward0>)\n",
      "tensor([2.0316], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4025], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0058], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6090], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2142], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2043], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1943], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1844], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1744], grad_fn=<AddBackward0>)\n",
      "Epoch number: 57 W: 0.9879972338676453 B: 0.9934344291687012\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8788], grad_fn=<MulBackward0>)\n",
      "tensor([2.0313], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4020], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0053], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6085], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2137], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2038], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1938], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1839], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1739], grad_fn=<AddBackward0>)\n",
      "Epoch number: 58 W: 0.9877870082855225 B: 0.993320643901825\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8788], grad_fn=<MulBackward0>)\n",
      "tensor([2.0310], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4015], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0048], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6080], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2132], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2033], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1933], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1834], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1734], grad_fn=<AddBackward0>)\n",
      "Epoch number: 59 W: 0.9875766634941101 B: 0.9932068586349487\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8788], grad_fn=<MulBackward0>)\n",
      "tensor([2.0308], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9974], grad_fn=<MulBackward0>)\n",
      "tensor([6.4010], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0042], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6075], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2127], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2027], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1928], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1828], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1729], grad_fn=<AddBackward0>)\n",
      "Epoch number: 60 W: 0.9873661994934082 B: 0.9930930137634277\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8787], grad_fn=<MulBackward0>)\n",
      "tensor([2.0305], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.4005], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0037], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6070], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2122], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2022], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1923], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1823], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1724], grad_fn=<AddBackward0>)\n",
      "Epoch number: 61 W: 0.9871556162834167 B: 0.9929791688919067\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8787], grad_fn=<MulBackward0>)\n",
      "tensor([2.0302], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.4000], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0032], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6065], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2117], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2017], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1918], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1818], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1719], grad_fn=<AddBackward0>)\n",
      "Epoch number: 62 W: 0.9869449138641357 B: 0.9928653240203857\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8787], grad_fn=<MulBackward0>)\n",
      "tensor([2.0300], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3995], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0027], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6060], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2111], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2012], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1912], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1813], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1713], grad_fn=<AddBackward0>)\n",
      "Epoch number: 63 W: 0.98673415184021 B: 0.99275141954422\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8786], grad_fn=<MulBackward0>)\n",
      "tensor([2.0297], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3989], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0022], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6054], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2106], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2007], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1907], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1808], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1708], grad_fn=<AddBackward0>)\n",
      "Epoch number: 64 W: 0.9865232706069946 B: 0.9926375150680542\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8786], grad_fn=<MulBackward0>)\n",
      "tensor([2.0294], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3984], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0017], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6049], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2101], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2001], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1902], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1802], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1703], grad_fn=<AddBackward0>)\n",
      "Epoch number: 65 W: 0.9863122701644897 B: 0.9925236105918884\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8786], grad_fn=<MulBackward0>)\n",
      "tensor([2.0292], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3979], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0012], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6044], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2096], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1996], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1897], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1797], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1698], grad_fn=<AddBackward0>)\n",
      "Epoch number: 66 W: 0.9861011505126953 B: 0.9924096465110779\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8785], grad_fn=<MulBackward0>)\n",
      "tensor([2.0289], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3974], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0007], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6039], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2091], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1991], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1892], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1792], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1693], grad_fn=<AddBackward0>)\n",
      "Epoch number: 67 W: 0.9858899116516113 B: 0.9922956824302673\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8785], grad_fn=<MulBackward0>)\n",
      "tensor([2.0287], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3969], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([11.0001], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6034], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2085], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1986], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1886], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1787], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1687], grad_fn=<AddBackward0>)\n",
      "Epoch number: 68 W: 0.9856785535812378 B: 0.9921817183494568\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8785], grad_fn=<MulBackward0>)\n",
      "tensor([2.0284], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3964], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9996], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6029], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2080], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1981], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1881], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1782], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1682], grad_fn=<AddBackward0>)\n",
      "Epoch number: 69 W: 0.9854670763015747 B: 0.9920676946640015\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8784], grad_fn=<MulBackward0>)\n",
      "tensor([2.0281], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3959], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9991], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6023], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2075], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1976], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1876], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1777], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1677], grad_fn=<AddBackward0>)\n",
      "Epoch number: 70 W: 0.9852554798126221 B: 0.9919536709785461\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8784], grad_fn=<MulBackward0>)\n",
      "tensor([2.0279], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3954], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9986], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6018], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2070], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1970], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1871], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1771], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1672], grad_fn=<AddBackward0>)\n",
      "Epoch number: 71 W: 0.9850437641143799 B: 0.991839587688446\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8783], grad_fn=<MulBackward0>)\n",
      "tensor([2.0276], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3949], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9981], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6013], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2065], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1965], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1866], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1766], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1667], grad_fn=<AddBackward0>)\n",
      "Epoch number: 72 W: 0.9848319292068481 B: 0.991725504398346\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8783], grad_fn=<MulBackward0>)\n",
      "tensor([2.0273], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3944], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9976], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6008], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2060], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1960], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1861], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1761], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1662], grad_fn=<AddBackward0>)\n",
      "Epoch number: 73 W: 0.9846199750900269 B: 0.9916114211082458\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8783], grad_fn=<MulBackward0>)\n",
      "tensor([2.0271], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3938], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9970], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.6002], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2054], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1955], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1855], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1756], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1656], grad_fn=<AddBackward0>)\n",
      "Epoch number: 74 W: 0.984407901763916 B: 0.991497278213501\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8782], grad_fn=<MulBackward0>)\n",
      "tensor([2.0268], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3933], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9965], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5997], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2049], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1950], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1850], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1751], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1651], grad_fn=<AddBackward0>)\n",
      "Epoch number: 75 W: 0.9841957092285156 B: 0.9913831353187561\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8782], grad_fn=<MulBackward0>)\n",
      "tensor([2.0265], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3928], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9960], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5992], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2044], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1944], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1845], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1745], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1646], grad_fn=<AddBackward0>)\n",
      "Epoch number: 76 W: 0.9839833974838257 B: 0.9912689924240112\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8782], grad_fn=<MulBackward0>)\n",
      "tensor([2.0263], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3923], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9955], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5987], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2039], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1939], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1840], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1740], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1641], grad_fn=<AddBackward0>)\n",
      "Epoch number: 77 W: 0.9837709665298462 B: 0.9911547899246216\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8781], grad_fn=<MulBackward0>)\n",
      "tensor([2.0260], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3918], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9950], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5982], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2033], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1934], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1834], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1735], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1635], grad_fn=<AddBackward0>)\n",
      "Epoch number: 78 W: 0.9835584163665771 B: 0.9910405874252319\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8781], grad_fn=<MulBackward0>)\n",
      "tensor([2.0257], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3913], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9944], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5976], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2028], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1929], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1829], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1729], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1630], grad_fn=<AddBackward0>)\n",
      "Epoch number: 79 W: 0.9833457469940186 B: 0.9909263849258423\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8781], grad_fn=<MulBackward0>)\n",
      "tensor([2.0255], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3908], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9939], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5971], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2023], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1923], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1824], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1724], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1625], grad_fn=<AddBackward0>)\n",
      "Epoch number: 80 W: 0.9831330180168152 B: 0.9908121228218079\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8780], grad_fn=<MulBackward0>)\n",
      "tensor([2.0252], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3902], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9934], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5966], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2018], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1918], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1819], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1719], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1620], grad_fn=<AddBackward0>)\n",
      "Epoch number: 81 W: 0.9829201698303223 B: 0.9906978607177734\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8780], grad_fn=<MulBackward0>)\n",
      "tensor([2.0249], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3897], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9929], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5961], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2012], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1913], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1813], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1714], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1614], grad_fn=<AddBackward0>)\n",
      "Epoch number: 82 W: 0.9827072024345398 B: 0.990583598613739\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8780], grad_fn=<MulBackward0>)\n",
      "tensor([2.0247], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3892], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9924], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5955], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2007], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1908], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1808], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1709], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1609], grad_fn=<AddBackward0>)\n",
      "Epoch number: 83 W: 0.9824941158294678 B: 0.9904692769050598\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8779], grad_fn=<MulBackward0>)\n",
      "tensor([2.0244], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3887], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9918], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5950], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.2002], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1902], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1803], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1703], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1604], grad_fn=<AddBackward0>)\n",
      "Epoch number: 84 W: 0.9822809100151062 B: 0.9903549551963806\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8779], grad_fn=<MulBackward0>)\n",
      "tensor([2.0242], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3882], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9913], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5945], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1996], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1897], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1797], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1698], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1598], grad_fn=<AddBackward0>)\n",
      "Epoch number: 85 W: 0.9820675849914551 B: 0.9902406334877014\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8779], grad_fn=<MulBackward0>)\n",
      "tensor([2.0239], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3876], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9908], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5940], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1991], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1892], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1792], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1693], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1593], grad_fn=<AddBackward0>)\n",
      "Epoch number: 86 W: 0.9818541407585144 B: 0.9901262521743774\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8778], grad_fn=<MulBackward0>)\n",
      "tensor([2.0236], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3871], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9903], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5934], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1986], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1886], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1787], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1687], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1588], grad_fn=<AddBackward0>)\n",
      "Epoch number: 87 W: 0.9816405773162842 B: 0.9900118708610535\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8778], grad_fn=<MulBackward0>)\n",
      "tensor([2.0234], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3866], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9898], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5929], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1981], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1881], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1782], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1682], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1583], grad_fn=<AddBackward0>)\n",
      "Epoch number: 88 W: 0.9814268946647644 B: 0.9898974299430847\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8778], grad_fn=<MulBackward0>)\n",
      "tensor([2.0231], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3861], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9892], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5924], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1976], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1876], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1777], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1677], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1578], grad_fn=<AddBackward0>)\n",
      "Epoch number: 89 W: 0.9812130928039551 B: 0.989782989025116\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8777], grad_fn=<MulBackward0>)\n",
      "tensor([2.0228], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3856], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9887], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5918], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1970], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1871], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1771], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1672], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1572], grad_fn=<AddBackward0>)\n",
      "Epoch number: 90 W: 0.9809991717338562 B: 0.9896685481071472\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8777], grad_fn=<MulBackward0>)\n",
      "tensor([2.0226], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3850], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9882], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5913], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1965], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1865], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1766], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1666], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1567], grad_fn=<AddBackward0>)\n",
      "Epoch number: 91 W: 0.9807851314544678 B: 0.9895540475845337\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8776], grad_fn=<MulBackward0>)\n",
      "tensor([2.0223], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9973], grad_fn=<MulBackward0>)\n",
      "tensor([6.3845], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9877], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5908], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1959], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1860], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1760], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1661], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1561], grad_fn=<AddBackward0>)\n",
      "Epoch number: 92 W: 0.9805709719657898 B: 0.9894395470619202\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8776], grad_fn=<MulBackward0>)\n",
      "tensor([2.0220], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3840], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9871], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5903], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1954], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1855], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1755], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1656], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1556], grad_fn=<AddBackward0>)\n",
      "Epoch number: 93 W: 0.9803566932678223 B: 0.9893250465393066\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8776], grad_fn=<MulBackward0>)\n",
      "tensor([2.0218], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3835], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9866], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5897], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1949], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1850], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1750], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1651], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1551], grad_fn=<AddBackward0>)\n",
      "Epoch number: 94 W: 0.9801422953605652 B: 0.9892104864120483\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8775], grad_fn=<MulBackward0>)\n",
      "tensor([2.0215], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3830], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9861], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5892], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1943], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1844], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1744], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1645], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1545], grad_fn=<AddBackward0>)\n",
      "Epoch number: 95 W: 0.9799277782440186 B: 0.98909592628479\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8775], grad_fn=<MulBackward0>)\n",
      "tensor([2.0212], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3824], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9855], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5887], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1938], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1839], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1739], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1640], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1540], grad_fn=<AddBackward0>)\n",
      "Epoch number: 96 W: 0.9797131419181824 B: 0.9889813661575317\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8775], grad_fn=<MulBackward0>)\n",
      "tensor([2.0210], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3819], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9850], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5881], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1933], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1833], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1734], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1634], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1535], grad_fn=<AddBackward0>)\n",
      "Epoch number: 97 W: 0.9794983863830566 B: 0.9888667464256287\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8774], grad_fn=<MulBackward0>)\n",
      "tensor([2.0207], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3814], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9845], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5876], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1928], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1828], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1729], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1629], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1530], grad_fn=<AddBackward0>)\n",
      "Epoch number: 98 W: 0.9792835116386414 B: 0.9887521266937256\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8774], grad_fn=<MulBackward0>)\n",
      "tensor([2.0204], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3809], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9840], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5871], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1922], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1823], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1723], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1624], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1524], grad_fn=<AddBackward0>)\n",
      "Epoch number: 99 W: 0.9790685176849365 B: 0.9886374473571777\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8774], grad_fn=<MulBackward0>)\n",
      "tensor([2.0202], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3803], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9834], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5865], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1917], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1817], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1718], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1618], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1519], grad_fn=<AddBackward0>)\n",
      "Epoch number: 100 W: 0.9788534045219421 B: 0.9885227680206299\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8773], grad_fn=<MulBackward0>)\n",
      "tensor([2.0199], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3798], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9829], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5860], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1912], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1812], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1713], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1613], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1514], grad_fn=<AddBackward0>)\n",
      "Epoch number: 101 W: 0.9786381721496582 B: 0.988408088684082\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8773], grad_fn=<MulBackward0>)\n",
      "tensor([2.0196], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3793], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9824], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5855], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1906], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1807], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1707], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1608], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1508], grad_fn=<AddBackward0>)\n",
      "Epoch number: 102 W: 0.9784228205680847 B: 0.9882933497428894\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8773], grad_fn=<MulBackward0>)\n",
      "tensor([2.0193], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3788], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9818], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5849], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1901], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1801], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1702], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1602], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1503], grad_fn=<AddBackward0>)\n",
      "Epoch number: 103 W: 0.9782073497772217 B: 0.9881786108016968\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8772], grad_fn=<MulBackward0>)\n",
      "tensor([2.0191], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3782], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9813], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5844], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1896], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1796], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1697], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1597], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1497], grad_fn=<AddBackward0>)\n",
      "Epoch number: 104 W: 0.9779917597770691 B: 0.9880638718605042\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8772], grad_fn=<MulBackward0>)\n",
      "tensor([2.0188], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3777], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9808], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5838], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1890], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1791], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1691], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1591], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1492], grad_fn=<AddBackward0>)\n",
      "Epoch number: 105 W: 0.977776050567627 B: 0.9879490733146667\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8772], grad_fn=<MulBackward0>)\n",
      "tensor([2.0185], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3772], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9802], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5833], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1885], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1785], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1686], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1586], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1487], grad_fn=<AddBackward0>)\n",
      "Epoch number: 106 W: 0.9775602221488953 B: 0.9878342747688293\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8771], grad_fn=<MulBackward0>)\n",
      "tensor([2.0183], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3767], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9797], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5828], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1879], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1780], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1680], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1581], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1481], grad_fn=<AddBackward0>)\n",
      "Epoch number: 107 W: 0.977344274520874 B: 0.9877194762229919\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8771], grad_fn=<MulBackward0>)\n",
      "tensor([2.0180], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3761], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9792], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5822], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1874], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1774], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1675], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1575], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1476], grad_fn=<AddBackward0>)\n",
      "Epoch number: 108 W: 0.9771282076835632 B: 0.9876046180725098\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8770], grad_fn=<MulBackward0>)\n",
      "tensor([2.0177], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3756], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9786], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5817], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1869], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1769], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1670], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1570], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1471], grad_fn=<AddBackward0>)\n",
      "Epoch number: 109 W: 0.9769119620323181 B: 0.9874897599220276\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8770], grad_fn=<MulBackward0>)\n",
      "tensor([2.0175], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3751], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9781], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5811], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1863], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1764], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1664], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1565], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1465], grad_fn=<AddBackward0>)\n",
      "Epoch number: 110 W: 0.9766955971717834 B: 0.9873748421669006\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8770], grad_fn=<MulBackward0>)\n",
      "tensor([2.0172], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3745], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9776], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5806], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1858], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1758], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1659], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1559], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1460], grad_fn=<AddBackward0>)\n",
      "Epoch number: 111 W: 0.9764791131019592 B: 0.9872599244117737\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8769], grad_fn=<MulBackward0>)\n",
      "tensor([2.0169], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3740], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9770], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5801], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1852], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1753], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1653], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1554], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1454], grad_fn=<AddBackward0>)\n",
      "Epoch number: 112 W: 0.9762625098228455 B: 0.9871450066566467\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8769], grad_fn=<MulBackward0>)\n",
      "tensor([2.0167], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3735], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9765], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5795], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1847], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1747], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1648], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1548], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1449], grad_fn=<AddBackward0>)\n",
      "Epoch number: 113 W: 0.9760457873344421 B: 0.987030029296875\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8769], grad_fn=<MulBackward0>)\n",
      "tensor([2.0164], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3729], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9760], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5790], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1842], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1742], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1643], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1543], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1444], grad_fn=<AddBackward0>)\n",
      "Epoch number: 114 W: 0.9758289456367493 B: 0.9869150519371033\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8768], grad_fn=<MulBackward0>)\n",
      "tensor([2.0161], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3724], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9754], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5784], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1836], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1737], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1637], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1538], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1438], grad_fn=<AddBackward0>)\n",
      "Epoch number: 115 W: 0.9756119847297668 B: 0.9868000745773315\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8768], grad_fn=<MulBackward0>)\n",
      "tensor([2.0159], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3719], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9749], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5779], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1831], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1731], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1632], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1532], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1433], grad_fn=<AddBackward0>)\n",
      "Epoch number: 116 W: 0.9753949046134949 B: 0.986685037612915\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8768], grad_fn=<MulBackward0>)\n",
      "tensor([2.0156], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3713], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9743], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5773], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1825], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1726], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1626], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1527], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1427], grad_fn=<AddBackward0>)\n",
      "Epoch number: 117 W: 0.9751777052879333 B: 0.9865700006484985\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8767], grad_fn=<MulBackward0>)\n",
      "tensor([2.0153], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3708], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9738], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5768], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1820], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1720], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1621], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1521], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1422], grad_fn=<AddBackward0>)\n",
      "Epoch number: 118 W: 0.9749603867530823 B: 0.986454963684082\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8767], grad_fn=<MulBackward0>)\n",
      "tensor([2.0150], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3703], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9733], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5763], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1814], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1715], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1615], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1516], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1416], grad_fn=<AddBackward0>)\n",
      "Epoch number: 119 W: 0.9747429490089417 B: 0.9863398671150208\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8767], grad_fn=<MulBackward0>)\n",
      "tensor([2.0148], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3697], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9727], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5757], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1809], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1709], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1610], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1510], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1411], grad_fn=<AddBackward0>)\n",
      "Epoch number: 120 W: 0.9745253920555115 B: 0.9862247705459595\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8766], grad_fn=<MulBackward0>)\n",
      "tensor([2.0145], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3692], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9722], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5752], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1804], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1704], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1605], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1505], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1406], grad_fn=<AddBackward0>)\n",
      "Epoch number: 121 W: 0.9743077158927917 B: 0.9861096143722534\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8766], grad_fn=<MulBackward0>)\n",
      "tensor([2.0142], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9972], grad_fn=<MulBackward0>)\n",
      "tensor([6.3687], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9716], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5746], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1798], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1698], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1599], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1499], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1400], grad_fn=<AddBackward0>)\n",
      "Epoch number: 122 W: 0.9740899205207825 B: 0.9859944581985474\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8765], grad_fn=<MulBackward0>)\n",
      "tensor([2.0140], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3681], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9711], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5741], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1793], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1693], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1594], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1494], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1395], grad_fn=<AddBackward0>)\n",
      "Epoch number: 123 W: 0.9738720059394836 B: 0.9858793020248413\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8765], grad_fn=<MulBackward0>)\n",
      "tensor([2.0137], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3676], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9706], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5735], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1787], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1687], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1588], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1488], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1389], grad_fn=<AddBackward0>)\n",
      "Epoch number: 124 W: 0.9736539721488953 B: 0.9857640862464905\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8765], grad_fn=<MulBackward0>)\n",
      "tensor([2.0134], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3671], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9700], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5730], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1782], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1682], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1583], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1483], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1384], grad_fn=<AddBackward0>)\n",
      "Epoch number: 125 W: 0.9734357595443726 B: 0.9856488704681396\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8764], grad_fn=<MulBackward0>)\n",
      "tensor([2.0132], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3665], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9695], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5725], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1776], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1677], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1577], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1478], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1378], grad_fn=<AddBackward0>)\n",
      "Epoch number: 126 W: 0.9732174277305603 B: 0.9855336546897888\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8764], grad_fn=<MulBackward0>)\n",
      "tensor([2.0129], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3660], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9689], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5719], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1771], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1671], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1572], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1472], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1373], grad_fn=<AddBackward0>)\n",
      "Epoch number: 127 W: 0.9729989767074585 B: 0.9854183793067932\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8764], grad_fn=<MulBackward0>)\n",
      "tensor([2.0126], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3654], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9684], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5714], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1765], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1666], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1566], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1467], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1367], grad_fn=<AddBackward0>)\n",
      "Epoch number: 128 W: 0.9727804064750671 B: 0.9853031039237976\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8763], grad_fn=<MulBackward0>)\n",
      "tensor([2.0123], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3649], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9678], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5708], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1760], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1660], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1561], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1461], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1362], grad_fn=<AddBackward0>)\n",
      "Epoch number: 129 W: 0.9725617170333862 B: 0.9851877689361572\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8763], grad_fn=<MulBackward0>)\n",
      "tensor([2.0121], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3644], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9673], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5702], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1754], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1655], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1555], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1456], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1356], grad_fn=<AddBackward0>)\n",
      "Epoch number: 130 W: 0.9723429083824158 B: 0.9850724339485168\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8763], grad_fn=<MulBackward0>)\n",
      "tensor([2.0118], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3638], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9668], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5697], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1749], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1649], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1550], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1450], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1351], grad_fn=<AddBackward0>)\n",
      "Epoch number: 131 W: 0.9721239805221558 B: 0.9849570989608765\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8762], grad_fn=<MulBackward0>)\n",
      "tensor([2.0115], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3633], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9662], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5691], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1743], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1644], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1544], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1445], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1345], grad_fn=<AddBackward0>)\n",
      "Epoch number: 132 W: 0.9719049334526062 B: 0.9848417043685913\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8762], grad_fn=<MulBackward0>)\n",
      "tensor([2.0113], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3627], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9657], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5686], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1738], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1638], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1539], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1439], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1340], grad_fn=<AddBackward0>)\n",
      "Epoch number: 133 W: 0.9716857671737671 B: 0.9847263097763062\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8761], grad_fn=<MulBackward0>)\n",
      "tensor([2.0110], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3622], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9651], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5680], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1732], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1633], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1533], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1434], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1334], grad_fn=<AddBackward0>)\n",
      "Epoch number: 134 W: 0.9714664816856384 B: 0.984610915184021\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8761], grad_fn=<MulBackward0>)\n",
      "tensor([2.0107], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3616], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9646], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5675], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1727], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1627], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1528], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1428], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1329], grad_fn=<AddBackward0>)\n",
      "Epoch number: 135 W: 0.9712470769882202 B: 0.9844954609870911\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8761], grad_fn=<MulBackward0>)\n",
      "tensor([2.0104], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3611], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9640], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5669], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1721], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1621], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1522], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1422], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1323], grad_fn=<AddBackward0>)\n",
      "Epoch number: 136 W: 0.9710274934768677 B: 0.9843800067901611\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8760], grad_fn=<MulBackward0>)\n",
      "tensor([2.0102], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3606], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9635], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5664], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1716], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1616], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1516], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1417], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1317], grad_fn=<AddBackward0>)\n",
      "Epoch number: 137 W: 0.9708077907562256 B: 0.9842644929885864\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8760], grad_fn=<MulBackward0>)\n",
      "tensor([2.0099], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3600], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9629], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5658], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1710], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1610], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1511], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1411], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1312], grad_fn=<AddBackward0>)\n",
      "Epoch number: 138 W: 0.970587968826294 B: 0.9841489791870117\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8760], grad_fn=<MulBackward0>)\n",
      "tensor([2.0096], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3595], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9624], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5653], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1704], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1605], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1505], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1406], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1306], grad_fn=<AddBackward0>)\n",
      "Epoch number: 139 W: 0.9703680276870728 B: 0.984033465385437\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8759], grad_fn=<MulBackward0>)\n",
      "tensor([2.0094], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3589], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9618], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5647], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1699], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1599], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1500], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1400], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1301], grad_fn=<AddBackward0>)\n",
      "Epoch number: 140 W: 0.970147967338562 B: 0.9839178919792175\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8759], grad_fn=<MulBackward0>)\n",
      "tensor([2.0091], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3584], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9613], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5642], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1693], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1594], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1494], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1395], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1295], grad_fn=<AddBackward0>)\n",
      "Epoch number: 141 W: 0.9699277877807617 B: 0.983802318572998\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8759], grad_fn=<MulBackward0>)\n",
      "tensor([2.0088], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3578], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9607], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5636], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1688], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1588], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1489], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1389], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1290], grad_fn=<AddBackward0>)\n",
      "Epoch number: 142 W: 0.9697074890136719 B: 0.9836866855621338\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8758], grad_fn=<MulBackward0>)\n",
      "tensor([2.0085], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3573], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9602], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5630], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1682], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1583], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1483], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1384], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1284], grad_fn=<AddBackward0>)\n",
      "Epoch number: 143 W: 0.9694870710372925 B: 0.9835710525512695\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8758], grad_fn=<MulBackward0>)\n",
      "tensor([2.0083], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3567], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9596], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5625], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1677], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1577], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1478], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1378], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1279], grad_fn=<AddBackward0>)\n",
      "Epoch number: 144 W: 0.9692664742469788 B: 0.9834554195404053\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8757], grad_fn=<MulBackward0>)\n",
      "tensor([2.0080], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3562], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9591], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5619], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1671], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1571], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1472], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1372], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1273], grad_fn=<AddBackward0>)\n",
      "Epoch number: 145 W: 0.9690457582473755 B: 0.9833397269248962\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8757], grad_fn=<MulBackward0>)\n",
      "tensor([2.0077], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3556], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9585], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5614], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1665], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1566], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1466], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1367], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1267], grad_fn=<AddBackward0>)\n",
      "Epoch number: 146 W: 0.9688249230384827 B: 0.9832240343093872\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8757], grad_fn=<MulBackward0>)\n",
      "tensor([2.0075], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3551], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9579], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5608], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1660], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1560], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1461], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1361], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1262], grad_fn=<AddBackward0>)\n",
      "Epoch number: 147 W: 0.9686039686203003 B: 0.9831083416938782\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8756], grad_fn=<MulBackward0>)\n",
      "tensor([2.0072], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3546], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9574], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5603], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1654], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1555], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1455], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1356], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1256], grad_fn=<AddBackward0>)\n",
      "Epoch number: 148 W: 0.9683828949928284 B: 0.9829925894737244\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8756], grad_fn=<MulBackward0>)\n",
      "tensor([2.0069], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3540], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9568], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5597], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1648], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1549], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1449], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1350], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1250], grad_fn=<AddBackward0>)\n",
      "Epoch number: 149 W: 0.9681617021560669 B: 0.9828768372535706\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8756], grad_fn=<MulBackward0>)\n",
      "tensor([2.0066], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9971], grad_fn=<MulBackward0>)\n",
      "tensor([6.3534], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9563], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5591], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1643], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1543], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1444], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1344], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1245], grad_fn=<AddBackward0>)\n",
      "Epoch number: 150 W: 0.9679403901100159 B: 0.982761025428772\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8755], grad_fn=<MulBackward0>)\n",
      "tensor([2.0064], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3529], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9557], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5586], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1637], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1538], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1438], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1339], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1239], grad_fn=<AddBackward0>)\n",
      "Epoch number: 151 W: 0.9677188992500305 B: 0.9826452136039734\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8755], grad_fn=<MulBackward0>)\n",
      "tensor([2.0061], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3524], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9552], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5580], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1632], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1532], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1433], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1333], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1234], grad_fn=<AddBackward0>)\n",
      "Epoch number: 152 W: 0.9674972891807556 B: 0.9825294017791748\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8754], grad_fn=<MulBackward0>)\n",
      "tensor([2.0058], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3518], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9546], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5574], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1626], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1527], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1427], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1328], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1228], grad_fn=<AddBackward0>)\n",
      "Epoch number: 153 W: 0.9672755599021912 B: 0.9824135303497314\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8754], grad_fn=<MulBackward0>)\n",
      "tensor([2.0055], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3512], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9541], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5569], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1620], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1521], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1421], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1322], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1222], grad_fn=<AddBackward0>)\n",
      "Epoch number: 154 W: 0.9670537114143372 B: 0.9822976589202881\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8754], grad_fn=<MulBackward0>)\n",
      "tensor([2.0053], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3507], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9535], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5563], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1615], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1515], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1416], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1316], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1217], grad_fn=<AddBackward0>)\n",
      "Epoch number: 155 W: 0.9668317437171936 B: 0.9821817278862\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8753], grad_fn=<MulBackward0>)\n",
      "tensor([2.0050], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3501], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9529], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5557], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1609], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1510], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1410], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1311], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1211], grad_fn=<AddBackward0>)\n",
      "Epoch number: 156 W: 0.9666096568107605 B: 0.9820657968521118\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8753], grad_fn=<MulBackward0>)\n",
      "tensor([2.0047], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3496], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9524], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5552], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1604], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1504], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1405], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1305], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1206], grad_fn=<AddBackward0>)\n",
      "Epoch number: 157 W: 0.9663873910903931 B: 0.9819498658180237\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8753], grad_fn=<MulBackward0>)\n",
      "tensor([2.0044], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3490], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9518], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5546], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1598], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1498], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1399], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1299], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1200], grad_fn=<AddBackward0>)\n",
      "Epoch number: 158 W: 0.9661650061607361 B: 0.9818338751792908\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8752], grad_fn=<MulBackward0>)\n",
      "tensor([2.0042], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3485], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9513], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5540], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1592], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1493], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1393], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1294], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1194], grad_fn=<AddBackward0>)\n",
      "Epoch number: 159 W: 0.9659425020217896 B: 0.9817178845405579\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8752], grad_fn=<MulBackward0>)\n",
      "tensor([2.0039], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3479], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9507], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5535], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1586], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1487], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1387], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1288], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1188], grad_fn=<AddBackward0>)\n",
      "Epoch number: 160 W: 0.9657198786735535 B: 0.9816018342971802\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8752], grad_fn=<MulBackward0>)\n",
      "tensor([2.0036], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3474], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9501], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5529], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1581], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1481], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1382], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1282], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1183], grad_fn=<AddBackward0>)\n",
      "Epoch number: 161 W: 0.9654971361160278 B: 0.9814857840538025\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8751], grad_fn=<MulBackward0>)\n",
      "tensor([2.0033], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3468], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9496], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5523], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1575], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1476], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1376], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1277], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1177], grad_fn=<AddBackward0>)\n",
      "Epoch number: 162 W: 0.9652742147445679 B: 0.9813697338104248\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8751], grad_fn=<MulBackward0>)\n",
      "tensor([2.0031], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3463], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9490], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5518], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1570], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1470], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1371], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1271], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1171], grad_fn=<AddBackward0>)\n",
      "Epoch number: 163 W: 0.9650511741638184 B: 0.9812536239624023\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8750], grad_fn=<MulBackward0>)\n",
      "tensor([2.0028], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3457], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9485], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5512], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1564], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1464], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1365], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1265], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1166], grad_fn=<AddBackward0>)\n",
      "Epoch number: 164 W: 0.9648280143737793 B: 0.9811375141143799\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8750], grad_fn=<MulBackward0>)\n",
      "tensor([2.0025], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3451], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9479], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5506], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1558], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1459], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1359], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1260], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1160], grad_fn=<AddBackward0>)\n",
      "Epoch number: 165 W: 0.9646047353744507 B: 0.9810214042663574\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8750], grad_fn=<MulBackward0>)\n",
      "tensor([2.0023], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3446], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9473], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5501], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1553], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1453], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1354], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1254], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1155], grad_fn=<AddBackward0>)\n",
      "Epoch number: 166 W: 0.9643813371658325 B: 0.9809052348136902\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8749], grad_fn=<MulBackward0>)\n",
      "tensor([2.0020], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3440], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9468], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5495], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1547], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1447], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1348], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1248], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1149], grad_fn=<AddBackward0>)\n",
      "Epoch number: 167 W: 0.96415776014328 B: 0.980789065361023\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8749], grad_fn=<MulBackward0>)\n",
      "tensor([2.0017], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3435], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9462], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5489], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1541], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1442], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1342], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1243], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1143], grad_fn=<AddBackward0>)\n",
      "Epoch number: 168 W: 0.963934063911438 B: 0.9806728363037109\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8749], grad_fn=<MulBackward0>)\n",
      "tensor([2.0014], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3429], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9456], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5484], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1535], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1436], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1336], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1237], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1137], grad_fn=<AddBackward0>)\n",
      "Epoch number: 169 W: 0.9637102484703064 B: 0.9805566072463989\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8748], grad_fn=<MulBackward0>)\n",
      "tensor([2.0011], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3423], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9451], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5478], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1530], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1430], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1331], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1231], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1132], grad_fn=<AddBackward0>)\n",
      "Epoch number: 170 W: 0.9634863138198853 B: 0.9804403781890869\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8748], grad_fn=<MulBackward0>)\n",
      "tensor([2.0009], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3418], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9445], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5472], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1524], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1424], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1325], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1225], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1126], grad_fn=<AddBackward0>)\n",
      "Epoch number: 171 W: 0.9632622599601746 B: 0.9803240895271301\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8747], grad_fn=<MulBackward0>)\n",
      "tensor([2.0006], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3412], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9439], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5466], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1518], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1419], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1319], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1220], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1120], grad_fn=<AddBackward0>)\n",
      "Epoch number: 172 W: 0.9630380272865295 B: 0.9802078008651733\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8747], grad_fn=<MulBackward0>)\n",
      "tensor([2.0003], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3406], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9434], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5461], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1512], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1413], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1313], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1214], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1114], grad_fn=<AddBackward0>)\n",
      "Epoch number: 173 W: 0.962813675403595 B: 0.9800914525985718\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8747], grad_fn=<MulBackward0>)\n",
      "tensor([2.0000], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3401], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9428], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5455], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1507], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1407], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1308], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1208], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1109], grad_fn=<AddBackward0>)\n",
      "Epoch number: 174 W: 0.9625892043113708 B: 0.9799751043319702\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8746], grad_fn=<MulBackward0>)\n",
      "tensor([1.9998], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3395], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9422], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5449], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1501], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1401], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1302], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1202], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1103], grad_fn=<AddBackward0>)\n",
      "Epoch number: 175 W: 0.9623646140098572 B: 0.9798587560653687\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8746], grad_fn=<MulBackward0>)\n",
      "tensor([1.9995], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3390], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9417], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5443], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1495], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1396], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1296], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1197], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1097], grad_fn=<AddBackward0>)\n",
      "Epoch number: 176 W: 0.9621398448944092 B: 0.9797423481941223\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8746], grad_fn=<MulBackward0>)\n",
      "tensor([1.9992], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9970], grad_fn=<MulBackward0>)\n",
      "tensor([6.3384], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9411], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5438], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1489], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1390], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1290], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1191], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1091], grad_fn=<AddBackward0>)\n",
      "Epoch number: 177 W: 0.9619149565696716 B: 0.979625940322876\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8745], grad_fn=<MulBackward0>)\n",
      "tensor([1.9989], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3378], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9405], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5432], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1484], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1384], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1285], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1185], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1086], grad_fn=<AddBackward0>)\n",
      "Epoch number: 178 W: 0.9616899490356445 B: 0.9795094728469849\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8745], grad_fn=<MulBackward0>)\n",
      "tensor([1.9987], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3373], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9399], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5426], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1478], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1378], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1279], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1179], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1080], grad_fn=<AddBackward0>)\n",
      "Epoch number: 179 W: 0.9614648222923279 B: 0.9793930053710938\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8744], grad_fn=<MulBackward0>)\n",
      "tensor([1.9984], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3367], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9394], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5420], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1472], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1372], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1273], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1173], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1074], grad_fn=<AddBackward0>)\n",
      "Epoch number: 180 W: 0.9612395763397217 B: 0.9792765378952026\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8744], grad_fn=<MulBackward0>)\n",
      "tensor([1.9981], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3361], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9388], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5414], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1466], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1367], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1267], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1168], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1068], grad_fn=<AddBackward0>)\n",
      "Epoch number: 181 W: 0.9610141515731812 B: 0.9791600108146667\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8744], grad_fn=<MulBackward0>)\n",
      "tensor([1.9978], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3356], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9382], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5409], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1460], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1361], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1261], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1162], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1062], grad_fn=<AddBackward0>)\n",
      "Epoch number: 182 W: 0.9607886075973511 B: 0.9790434837341309\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8743], grad_fn=<MulBackward0>)\n",
      "tensor([1.9976], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3350], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9376], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5403], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1455], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1355], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1255], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1156], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1056], grad_fn=<AddBackward0>)\n",
      "Epoch number: 183 W: 0.9605629444122314 B: 0.9789268970489502\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8743], grad_fn=<MulBackward0>)\n",
      "tensor([1.9973], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3344], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9371], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5397], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1449], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1349], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1250], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1150], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1051], grad_fn=<AddBackward0>)\n",
      "Epoch number: 184 W: 0.9603371620178223 B: 0.9788103103637695\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8743], grad_fn=<MulBackward0>)\n",
      "tensor([1.9970], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3339], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9365], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5391], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1443], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1343], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1244], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1144], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1045], grad_fn=<AddBackward0>)\n",
      "Epoch number: 185 W: 0.9601112008094788 B: 0.9786937236785889\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8742], grad_fn=<MulBackward0>)\n",
      "tensor([1.9967], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3333], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9359], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5386], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1437], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1338], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1238], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1139], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1039], grad_fn=<AddBackward0>)\n",
      "Epoch number: 186 W: 0.9598851203918457 B: 0.9785770773887634\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8742], grad_fn=<MulBackward0>)\n",
      "tensor([1.9964], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3327], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9353], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5380], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1431], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1332], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1232], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1133], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1033], grad_fn=<AddBackward0>)\n",
      "Epoch number: 187 W: 0.9596589207649231 B: 0.978460431098938\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8741], grad_fn=<MulBackward0>)\n",
      "tensor([1.9962], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3321], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9348], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5374], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1426], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1326], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1227], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1127], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1028], grad_fn=<AddBackward0>)\n",
      "Epoch number: 188 W: 0.9594325423240662 B: 0.9783437252044678\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8741], grad_fn=<MulBackward0>)\n",
      "tensor([1.9959], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3316], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9342], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5368], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1420], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1320], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1221], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1121], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1022], grad_fn=<AddBackward0>)\n",
      "Epoch number: 189 W: 0.9592060446739197 B: 0.9782270193099976\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8741], grad_fn=<MulBackward0>)\n",
      "tensor([1.9956], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3310], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9336], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5362], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1414], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1314], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1215], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1115], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1016], grad_fn=<AddBackward0>)\n",
      "Epoch number: 190 W: 0.9589794278144836 B: 0.9781103134155273\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8740], grad_fn=<MulBackward0>)\n",
      "tensor([1.9953], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3304], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9330], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5356], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1408], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1308], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1209], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1109], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1010], grad_fn=<AddBackward0>)\n",
      "Epoch number: 191 W: 0.9587526917457581 B: 0.9779935479164124\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8740], grad_fn=<MulBackward0>)\n",
      "tensor([1.9951], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3299], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9325], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5350], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1402], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1303], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1203], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1104], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1004], grad_fn=<AddBackward0>)\n",
      "Epoch number: 192 W: 0.9585257768630981 B: 0.9778767824172974\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8740], grad_fn=<MulBackward0>)\n",
      "tensor([1.9948], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3293], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9319], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5345], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1396], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1297], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1197], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1098], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.0998], grad_fn=<AddBackward0>)\n",
      "Epoch number: 193 W: 0.9582987427711487 B: 0.9777599573135376\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8739], grad_fn=<MulBackward0>)\n",
      "tensor([1.9945], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3287], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9313], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5339], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1390], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1291], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1191], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1092], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.0992], grad_fn=<AddBackward0>)\n",
      "Epoch number: 194 W: 0.9580715894699097 B: 0.9776431322097778\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8739], grad_fn=<MulBackward0>)\n",
      "tensor([1.9942], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3281], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9307], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5333], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1384], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1285], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1185], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1086], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.0986], grad_fn=<AddBackward0>)\n",
      "Epoch number: 195 W: 0.9578442573547363 B: 0.9775262475013733\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8738], grad_fn=<MulBackward0>)\n",
      "tensor([1.9939], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3275], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9301], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5327], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1379], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1279], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1180], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1080], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.0981], grad_fn=<AddBackward0>)\n",
      "Epoch number: 196 W: 0.9576168060302734 B: 0.9774093627929688\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8738], grad_fn=<MulBackward0>)\n",
      "tensor([1.9937], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3270], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9295], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5321], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1373], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1273], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1174], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1074], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.0975], grad_fn=<AddBackward0>)\n",
      "Epoch number: 197 W: 0.957389235496521 B: 0.9772924780845642\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8738], grad_fn=<MulBackward0>)\n",
      "tensor([1.9934], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3264], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9290], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5315], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1367], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1267], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1168], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1068], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.0969], grad_fn=<AddBackward0>)\n",
      "Epoch number: 198 W: 0.957161545753479 B: 0.9771755337715149\n",
      "x:  tensor(1)\n",
      "y_out tensor([0.8737], grad_fn=<MulBackward0>)\n",
      "tensor([1.9931], grad_fn=<AddBackward0>)\n",
      "x:  tensor(5)\n",
      "y_out tensor([0.9969], grad_fn=<MulBackward0>)\n",
      "tensor([6.3258], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([10.9284], grad_fn=<AddBackward0>)\n",
      "x:  tensor(10)\n",
      "y_out tensor([1.0000], grad_fn=<MulBackward0>)\n",
      "tensor([15.5309], grad_fn=<AddBackward0>)\n",
      "x:  tensor(25)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1361], grad_fn=<AddBackward0>)\n",
      "x:  tensor(50)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1261], grad_fn=<AddBackward0>)\n",
      "x:  tensor(70)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1162], grad_fn=<AddBackward0>)\n",
      "x:  tensor(75)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.1062], grad_fn=<AddBackward0>)\n",
      "x:  tensor(100)\n",
      "y_out tensor([1.], grad_fn=<MulBackward0>)\n",
      "tensor([20.0963], grad_fn=<AddBackward0>)\n",
      "Epoch number: 199 W: 0.9569336771965027 B: 0.9770585894584656\n"
     ]
    }
   ],
   "source": [
    "#Implmenet logistic regression\n",
    "x = torch.tensor([1, 5, 10, 10, 25, 50, 70, 75, 100])\n",
    "y = torch.tensor([0, 0, 0, 0, 0, 1, 1, 1, 1])\n",
    "losses = []\n",
    "learning_rate = torch.tensor(0.001)\n",
    "w = torch.tensor([1.0], requires_grad = True)\n",
    "b = torch.tensor([1.0], requires_grad = True)\n",
    "\n",
    "for epoch in range(0, 200):\n",
    "    loss = 0.0\n",
    "    for data in range(0, len(x)):\n",
    "        a = w*x[data] + b\n",
    "        y_out = 1/(1 + torch.exp(-a))\n",
    "        print(\"x: \", x[data])\n",
    "        print(\"y_out\", y_out)\n",
    "        loss += - y[data]*torch.log(y_out + 0.01) - (1 - y[data])*torch.log(1 - y_out + 0.01)\n",
    "        print(loss)\n",
    "    loss = loss/len(x)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "        b -= learning_rate*b.grad\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    print(\"Epoch number: \" + str(epoch) + \" W: \" + str(w.item()) + \" B: \" + str(b.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b6d4d4-d0a6-4fdd-b947-a7adcb377deb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1706064180851,
     "user": {
      "displayName": "Aarushi Dharna",
      "userId": "00345604244750873612"
     },
     "user_tz": -330
    },
    "id": "a4b6d4d4-d0a6-4fdd-b947-a7adcb377deb",
    "outputId": "45b6ef03-18bb-4311-8dd2-bb3490ddc209"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGsCAYAAAAPJKchAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAq9UlEQVR4nO3df3xU9Z3v8fckJBN+JIEI+QEECKAgAgFRQrQKLlTkIgvqetnWvUFW8aENvVBsu2JXrba78cdF6bZU6rpKu4ooKnCl1orBhKsELT9Sflij2JSgJAFUMpNAJmHme/+AmRAhkAkh3zmT1/PxmIeZM+fkfHI8j8e8+Z7P+R6XMcYIAADAkhjbBQAAgM6NMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsclQY2bRpk2bMmKG+ffvK5XJp7dq1YW1fVFSkmTNnKiMjQ927d9eYMWP04osvNltnz549uuWWWzRo0CC5XC4tXbq0/f4AAABwGkeFkbq6OmVnZ2vZsmVt2n7z5s0aPXq0XnvtNe3cuVNz585VXl6e1q9fH1rn6NGjGjx4sB599FGlp6e3V+kAAKAFLqc+KM/lcmnNmjWaNWtWaJnP59NPfvITvfTSSzpy5IhGjhypxx57TJMmTWrx90yfPl1paWl67rnnTvts0KBBWrhwoRYuXNj+fwAAAJDksJGRc5k/f75KSkq0atUq7dy5U7feeqtuuOEGffrppy1uU1NTo5SUlA6sEgAAnCpqwkhFRYWef/55rV69Wtdcc42GDBmiH/7wh/rWt76l559//ozbvPLKK/rTn/6kuXPndnC1AAAgqIvtAtrLrl275Pf7dckllzRb7vP5dNFFF522/rvvvqu5c+fqP//zP3XZZZd1VJkAAOAboiaM1NbWKjY2Vtu2bVNsbGyzz3r06NHsfXFxsWbMmKGnnnpKeXl5HVkmAAD4hqgJI2PHjpXf79fBgwd1zTXXtLheUVGRbrzxRj322GO66667OrBCAABwJo4KI7W1tdq7d2/ofXl5uUpLS5WSkqJLLrlEt912m/Ly8rRkyRKNHTtWhw4dUmFhoUaPHq3p06fr3Xff1Y033qgFCxbolltuUVVVlSQpPj4+1MTa0NCgjz76KPTzF198odLSUvXo0UNDhw7t+D8aAIAo56hbe4uKinTdddedtnzOnDlasWKFGhsb9fOf/1y/+93v9MUXX6h3796aMGGCHn74YY0aNUq33367fvvb3562/cSJE1VUVCRJ+tvf/qasrKyzrgMAANqPo8IIAACIPlFzay8AAHAmwggAALDKEQ2sgUBABw4cUGJiolwul+1yAABAKxhj5PV61bdvX8XEtDz+4YgwcuDAAWVmZtouAwAAtMH+/fvVv3//Fj93RBhJTEyUdOKPSUpKslwNAABoDY/Ho8zMzND3eEscEUaCl2aSkpIIIwAAOMy5WixoYAUAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFjliAflAQCAC2PpO5+otv64/lfuQA28qLuVGhgZAQCgE3t12+d69r1yfVnXYK0GwggAAJ1Yre+4JCnRbe9iCWEEAIBOyhgjb/3JMJIQZ60OwggAAJ1UfWNA/oCRJPVIYGQEAAB0MG99oyTJ5ZK6x8daq4MwAgBAJ+U92S/Sw91FLpfLWh2EEQAAOqlQv4jF5lWJMAIAQKdVGwHNqxJhBACATqvWd6JnxGbzqhRmGCkoKNCVV16pxMREpaamatasWSorKzvrNitWrJDL5Wr2SkhIOK+iAQDA+fOERkYcFEaKi4uVn5+vLVu2aMOGDWpsbNT111+vurq6s26XlJSkysrK0Gvfvn3nVTQAADh/wcs0PSz3jIS197feeqvZ+xUrVig1NVXbtm3Ttdde2+J2LpdL6enpbasQAABcEJEw4Zl0nj0jNTU1kqSUlJSzrldbW6uBAwcqMzNTM2fO1J49e866vs/nk8fjafYCAADtK9gz4qjLNKcKBAJauHChrr76ao0cObLF9YYNG6bnnntO69at0wsvvKBAIKCrrrpKn3/+eYvbFBQUKDk5OfTKzMxsa5kAAKAF3gi5TNPmMJKfn6/du3dr1apVZ10vNzdXeXl5GjNmjCZOnKjXX39dffr00W9+85sWt1m8eLFqampCr/3797e1TAAA0ILgpGe2R0batPf58+dr/fr12rRpk/r37x/WtnFxcRo7dqz27t3b4jput1tut7stpQEAgFaKlAbWsEZGjDGaP3++1qxZo40bNyorKyvsHfr9fu3atUsZGRlhbwsAANpP8Nk0thtYw4pC+fn5WrlypdatW6fExERVVVVJkpKTk9W1a1dJUl5envr166eCggJJ0iOPPKIJEyZo6NChOnLkiJ544gnt27dPd955Zzv/KQAAIBy1TrxM8/TTT0uSJk2a1Gz5888/r9tvv12SVFFRoZiYpgGXr7/+WvPmzVNVVZV69eqlcePGafPmzRoxYsT5VQ4AAM6LN0ImPQtr78aYc65TVFTU7P1TTz2lp556KqyiAADAhefInhEAABAdAgGj2oaTYcSp84wAAADnqms4ruAFjyQnz8AKAACcKdi82iXGJXcXu3GAMAIAQCd0avOqy+WyWgthBACATig0FbzlfhGJMAIAQKcUmvDMbbdfRCKMAADQKQV7RhgZAQAAVgQv0yQRRgAAgA2RMuGZRBgBAKBT8nKZBgAA2BQpT+yVCCMAAHRKXKYBAABW0cAKAACs4tZeAABgFZOeAQAAq7ibBgAAWOWlgRUAANhUG2pg5TINAADoYMf9AR1r9EviMg0AALAgeCeNxGUaAABgQbBfxN0lRvFd7EcB+xUAAIAOFQwjkTAVvEQYAQCg0wlepkmMgH4RiTACAECnE5zwLBL6RSTCCAAAnQ4jIwAAwKpImvBMIowAANDp0MAKAACsqvWdfEgel2kAAIANTSMjhBEAAGBBLT0jAADAJg89IwAAwKZgz0gkPCRPIowAANDphOYZ4TINAACwgQZWAABgVaiBlTACAABsYNIzAABgje+4Xw3+gCRu7QUAABYER0UkwggAALAg2C/SPT5WsTEuy9WcQBgBAKATCd7WGynNqxJhBACATsVTH3xIXmQ0r0qEEQAAOpVIey6NRBgBAKBTibQJzyTCCAAAnUpoKnjCCAAAsMEb7Blx0zMCAAAs8HI3DQAAsMlLAysAALCplgZWAABgEw2sAADAKi+TngEAAJvoGQEAAFYx6RkAALCKnhEAAGCNMeaUMOLQnpGCggJdeeWVSkxMVGpqqmbNmqWysrJzbrd69WoNHz5cCQkJGjVqlN588802FwwAANrmWKNf/oCR5OCekeLiYuXn52vLli3asGGDGhsbdf3116uurq7FbTZv3qzvfOc7uuOOO7Rjxw7NmjVLs2bN0u7du8+7eAAA0HrBOUZiXFK3+FjL1TRxGWNMWzc+dOiQUlNTVVxcrGuvvfaM68yePVt1dXVav359aNmECRM0ZswYLV++vFX78Xg8Sk5OVk1NjZKSktpaLgAAndreg7Wa8mSxkhK6aOdPp17w/bX2+/u8ekZqamokSSkpKS2uU1JSoilTpjRbNnXqVJWUlLS4jc/nk8fjafYCAADnJxL7RaTzCCOBQEALFy7U1VdfrZEjR7a4XlVVldLS0potS0tLU1VVVYvbFBQUKDk5OfTKzMxsa5kAAOCkpgnPIqdfRDqPMJKfn6/du3dr1apV7VmPJGnx4sWqqakJvfbv39/u+wAAoLOpjcAJzySpTdXMnz9f69ev16ZNm9S/f/+zrpuenq7q6upmy6qrq5Went7iNm63W263uy2lAQCAFkTihGdSmCMjxhjNnz9fa9as0caNG5WVlXXObXJzc1VYWNhs2YYNG5SbmxtepQAA4Lx4T/aM9IiwnpGwolF+fr5WrlypdevWKTExMdT3kZycrK5du0qS8vLy1K9fPxUUFEiSFixYoIkTJ2rJkiWaPn26Vq1apa1bt+qZZ55p5z8FAACcTaRepglrZOTpp59WTU2NJk2apIyMjNDr5ZdfDq1TUVGhysrK0PurrrpKK1eu1DPPPKPs7Gy9+uqrWrt27VmbXgEAQPsLNrAmRdhlmrCqac2UJEVFRactu/XWW3XrrbeGsysAANDOgrf2OnpkBAAAOFdUNLACAADnitQGVsIIAACdRNRNegYAAJwleDdNIj0jAADAhqaeES7TAAAAC0J303CZBgAAdLRAwHBrLwAAsKe24XjoZxpYAQBAhws2r8bFuuTuEllf/5FVDQAAuCBObV51uVyWq2mOMAIAQCdQ6zsxx0ik9YtIhBEAADoFT4ROBS8RRgAA6BSCPSOMjAAAACuCt/UyMgIAAKxoei5NZM2+KhFGAADoFLhMAwAArKKBFQAAWBWpz6WRCCMAAHQK9IwAAACrQnfT0DMCAABsoIEVAABY5aWBFQAA2OSlgRUAANgUbGBNooEVAAB0tEZ/QPWNAUn0jAAAAAuCzasSl2kAAIAFwdt6E+JiFBcbeV/9kVcRAABoV0130kRev4hEGAEAIOqFZl+NwH4RiTACAEDUi+Tn0kiEEQAAol4kT3gmEUYAAIh6oQnPuEwDAABsiOQn9kqEEQAAol4kPyRPIowAABD1gj0jSfSMAAAAG7ibBgAAWOUNXaahZwQAAFjQ1MDKyAgAALCAyzQAAMAqGlgBAIBVoZERekYAAEBHM8bQMwIAAOzxHQ+o0W8k0TMCAAAsCF6ikaTu8YQRAADQwbynTAUfG+OyXM2ZEUYAAIhikf5cGokwAgBAVIv05lWJMAIAQFTzRviEZxJhBACAqBbsGUlMiMw5RiTCCAAAUa02eJmGnhEAAGBD8NZeekYAAIAVXu6mAQAANtHACgAArIrKBtZNmzZpxowZ6tu3r1wul9auXXvW9YuKiuRyuU57VVVVtbVmAADQSlHZwFpXV6fs7GwtW7YsrO3KyspUWVkZeqWmpoa7awAAEKamkZHIDSNhVzZt2jRNmzYt7B2lpqaqZ8+eYW8HAADarpaekSZjxoxRRkaGvv3tb+v9998/67o+n08ej6fZCwAAhC8qe0bClZGRoeXLl+u1117Ta6+9pszMTE2aNEnbt29vcZuCggIlJyeHXpmZmRe6TAAAolLw2TSRfGuvyxhj2ryxy6U1a9Zo1qxZYW03ceJEDRgwQP/93/99xs99Pp98Pl/ovcfjUWZmpmpqapSUlNTWcgEA6FSMMRpy/5sKGOmD+ycrLSmhQ/fv8XiUnJx8zu9vKzFp/Pjxeu+991r83O12y+12d2BFAABEn6MNfgVODjlEcgOrlXlGSktLlZGRYWPXAAB0GsHm1dgYl7rGxVqupmVhx6Ta2lrt3bs39L68vFylpaVKSUnRgAEDtHjxYn3xxRf63e9+J0launSpsrKydNlll6m+vl7PPvusNm7cqLfffrv9/goAAHCaU/tFXC6X5WpaFnYY2bp1q6677rrQ+0WLFkmS5syZoxUrVqiyslIVFRWhzxsaGnTvvffqiy++ULdu3TR69Gi98847zX4HAABof054Lo10ng2sHaW1DTAAAKDJpk8OKe+5DzU8PVFvLby2w/ff2u9vnk0DAECUCvaMRHLzqkQYAQAgatU65DINYQQAgCjlCT4kL4JnX5UIIwAARC0nPJdGIowAABC1nPDEXokwAgBA1Ar2jCTSMwIAAGzw+ugZAQAAFjll0jPCCAAAUYp5RgAAgFWhkRHCCAAAsKGpgZWeEQAAYIE3NOkZIyMAAKCD+QNGdQ1+SVymAQAAFgSbVyVGRgAAgAXBMBIfGyN3l1jL1ZwdYQQAgChU65Cp4CXCCAAAUSnYvBrp/SISYQQAgKjk9Tlj9lWJMAIAQFRyyhN7JcIIAABRqTb0XJrInvBMIowAABCVgj0jSYyMAAAAG4K39tLACgAArKBnBAAAWOWlZwQAANhU62OeEQAAYFFwZIQGVgAAYEUtk54BAACbmhpY6RkBAAAWNDWwMjICAAAsCE56xq29AACgwzUcD8h3PCCJMAIAACyoO9m8KnGZBgAAWBDsF+kaF6susZH/VR/5FQIAgLB4HTThmUQYAQAg6jjpuTQSYQQAgKhTGwwjDugXkQgjAABEneBlGidMeCYRRgAAiDq1DprwTCKMAAAQdbw+ekYAAIBFoangCSMAAMAGGlgBAIBVTc+loYEVAABYUOvjMg0AALDIw6RnAADAJm7tBQAAVtWGbu2lZwQAAFjQ1MDKyAgAAOhgxpimBlYu0wAAgI7mOx5Qo99IYmQEAABYEJx91eWSuscTRgAAQAcL9ov0iO+imBiX5WpahzACAEAUcdqEZxJhBACAqOJ12IRnUhvCyKZNmzRjxgz17dtXLpdLa9euPec2RUVFuvzyy+V2uzV06FCtWLGiDaUCAIBz8TpswjOpDWGkrq5O2dnZWrZsWavWLy8v1/Tp03XdddeptLRUCxcu1J133qk//vGPYRcLAADOzmkTnklS2LFp2rRpmjZtWqvXX758ubKysrRkyRJJ0qWXXqr33ntPTz31lKZOnRru7gEAwFmEGlij+TJNuEpKSjRlypRmy6ZOnaqSkpIWt/H5fPJ4PM1eAADg3ILPpUmM5ss04aqqqlJaWlqzZWlpafJ4PDp27NgZtykoKFBycnLolZmZeaHLBAAgKnh9naCBtSMsXrxYNTU1odf+/fttlwQAgCM0NbBGcc9IuNLT01VdXd1sWXV1tZKSktS1a9czbuN2u+V2uy90aQAARB2nPSRP6oCRkdzcXBUWFjZbtmHDBuXm5l7oXQMA0Ol0iknPamtrVVpaqtLSUkknbt0tLS1VRUWFpBOXWPLy8kLr33333frrX/+qH//4x/r444/161//Wq+88op+8IMftM9fAAAAQoINrEnRHEa2bt2qsWPHauzYsZKkRYsWaezYsXrwwQclSZWVlaFgIklZWVn6/e9/rw0bNig7O1tLlizRs88+y229AABcAJ2iZ2TSpEkyxrT4+ZlmV500aZJ27NgR7q4AAECYOsVlGgAAELk8NLACAABbjDFN08Ez6RkAAOhodQ1+BTspnPRsGsIIAABRIngnTWyMSwlxzvmKd06lAADgrGp9Tf0iLpfLcjWtRxgBACBKeEK39TqnX0QijAAAEDVCT+x1UL+IRBgBACBqBCc8c9KdNBJhBACAqBHsGXHShGcSYQQAgKgRGhkhjAAAABu8NLACAACbvDSwAgAAm06dZ8RJCCMAAESJ0HNpCCMAAMAGekYAAIBVhBEAAGCVtz7YM0IDKwAAsICeEQAAYBWTngEAAGv8AaOjDX5J9IwAAAALgpdoJJ5NAwAALAg2r8Z3iZG7S6zlasJDGAEAIAqEmlcddolGIowAABAVnNq8KhFGAACICrXBCc8IIwAAwAZPcMIzt7MmPJMIIwAARIVgzwgjIwAAwIpaekYAAIBNoQZW7qYBAAA2ND2Xhp4RAABgQbCBlZ4RAABgRejWXi7TAAAAG5j0DAAAWNXUM0IYAQAAFtDACgAArAo+tZeeEQAAYAU9IwAAwJqG4wH5jgck8WwaAABgQbBfRJK6u2MtVtI2hBEAABwu2C/SLT5WXWKd99XuvIoBAEAzXgdPeCYRRgAAcDwnN69KhBEAABwv2DPSw4FzjEiEEQAAHK/Wd6JnJImREQAAYAM9IwAAwCrCCAAAsKqpgZWeEQAAYEGwZ6QHPSMAAMCG4MgIDawAAMCKWnpGAACATV4fPSMAAMCi0N00XKYBAAA2BBtYmQ4eAABYEbq1tzP1jCxbtkyDBg1SQkKCcnJy9OGHH7a47ooVK+RyuZq9EhIS2lwwAABoYoxpamDtLCMjL7/8shYtWqSHHnpI27dvV3Z2tqZOnaqDBw+2uE1SUpIqKytDr3379p1X0QAA4IT6xoCOB4ykTtTA+uSTT2revHmaO3euRowYoeXLl6tbt2567rnnWtzG5XIpPT099EpLSzuvogEAwAnek/0iLpfULS7WcjVtE1YYaWho0LZt2zRlypSmXxAToylTpqikpKTF7WprazVw4EBlZmZq5syZ2rNnz1n34/P55PF4mr0AAMDpTp1jJCbGZbmatgkrjBw+fFh+v/+0kY20tDRVVVWdcZthw4bpueee07p16/TCCy8oEAjoqquu0ueff97ifgoKCpScnBx6ZWZmhlMmAACdhtObV6UOuJsmNzdXeXl5GjNmjCZOnKjXX39dffr00W9+85sWt1m8eLFqampCr/3791/oMgEAcKRah094JklhxajevXsrNjZW1dXVzZZXV1crPT29Vb8jLi5OY8eO1d69e1tcx+12y+12h1MaAACdkrfe2Q/Jk8IcGYmPj9e4ceNUWFgYWhYIBFRYWKjc3NxW/Q6/369du3YpIyMjvEoBAMBpPMec/VwaKcyREUlatGiR5syZoyuuuELjx4/X0qVLVVdXp7lz50qS8vLy1K9fPxUUFEiSHnnkEU2YMEFDhw7VkSNH9MQTT2jfvn2688472/cvAQCgkznW4Nez7/1VkpSZ0tVyNW0XdhiZPXu2Dh06pAcffFBVVVUaM2aM3nrrrVBTa0VFhWJimgZcvv76a82bN09VVVXq1auXxo0bp82bN2vEiBHt91cAANAJPbButz6prlWfRLf+9+SLbZfTZi5jjLFdxLl4PB4lJyerpqZGSUlJtssBAMC6V7bu149f3akYl/TinROUO+Qi2yWdprXf3zybBgAAh/lLpUcPrN0tSbr3+mERGUTCQRgBAMBBan3Hlf/idvmOBzTxkj66Z+IQ2yWdN8IIAAAOYYzR4td36a+H65SRnKCnZo9x7KyrpyKMAADgEC98UKE3/nxAXWJc+tV3xyqle7ztktoFYQQAAAfY9XmNfvbGR5Kk+6YN17iBKZYraj+EEQAAIlzNsUZ9b+U2NfgD+vaINN3xrSzbJbUrwggAABHMGKMfrf6z9n91TJkpXfV//iFbLpfz+0RORRgBACCC/dd75Xr7o2rFx8Zo2XcvV3I35z4QryWEEQAAItS2fV/r0T98LEl64MZLNbp/T7sFXSCEEQAAItBXdQ2av3K7jgeMbhydoX+aMNB2SRcMYQQAgAgTCBgteqVUlTX1Gty7ux69ZXTU9YmcijACAECEebr4MxWVHZK7S4x+/U+Xq4c77OfaOgphBACACLLlr19qydtlkqSfzRqp4enR/4BYwggAABHikNen77+0QwEj/cO4/vqfV2TaLqlDEEYAAIgA/oDRglU7dMjr07C0RP1s5kjbJXUYwggAABHgF4WfavNnX6pbfKyW3Xa5usbH2i6pwxBGAACwbNMnh/TLjZ9KkgpuHqWhqT0sV9SxCCMAAFh05GiDFr1SKmOk23IGaOaYfrZL6nCEEQAALHrsrY91uLZBF6f20AM3jrBdjhWEEQAALNn6t6/00of7JUn/fvMoJcR1nj6RUxFGAACwoNEf0E/W7JYkzb4iU1cOSrFckT2EEQAALHj2/5WrrNqrlO7xum/acNvlWEUYAQCgg+3/6qh+UfiJJOkn/+NS9eoeb7kiuwgjAAB0IGOMHli3W/WNAeUOvkg3X9757p75JsIIAAAd6M1dVSoqO6T42Bj9/KaRUf003tYijAAA0EE89Y16+I09kqR7Jg3RkD6da3KzlhBGAADoIEv+WKaDXp+yenfXPZOG2C4nYhBGAADoAH/ef0S/27JPkvRvs0Z22jlFzoQwAgDABXbcH9D9a3bJGOmmsf101dDetkuKKIQRAAAusN+W7NOeAx4ld43TT6ZfaruciEMYAQDgAjpw5JiefLtMknTftOHq3cNtuaLIQxgBAOAC+un/3aO6Br+uGNhLs6/ItF1ORCKMAABwgWz4qFpvf1StLjEu/dtNoxQTw5wiZ0IYAQDgAqjzHddD6048CO/OawZrWHqi5YoiF2EEAIALYOk7n+hATb369+qqBZMvtl1ORCOMAADQzj464NFz7/9NkvSzWSPVNZ45Rc6GMAIAQDvyB4zuX7NL/oDR9FEZum5Yqu2SIh5hBACAdrTywwqV7j+iRHcXPThjhO1yHIEwAgBAOznordfjb30sSfrh1GFKS0qwXJEzEEYAAGgnP1v/F3nrj2t0/2T904SBtstxDMIIAADtoPiTQ3rjzwcU45L+/aZRimVOkVYjjAAAcJ7qG/16YO2JOUVuvypLI/slW67IWQgjAACch0Nen+747Z9U8dVRZSQnaNH1l9guyXG62C4AAACn2vzZYS1YVapDXp+6xsXq8X8YrR5uvlrDxREDACBM/oDRrzbu1S8KP1HASJek9dCvb7tcQ1OZ8r0tCCMAAIThkNenhS/v0Pt7v5Qk/c8r+uvhv2eW1fNBGAEAoJW+eVnm57NG6pZx/W2X5XiEEQAAzoHLMhcWYQQAgLP45mWZ2Vdk6qd/fxmXZdoRYQQAgBZs3ntYC15uuizzbzeN1M2Xc1mmvRFGAAD4Bn/A6JcbP9UvCj+VMdKwtEQtu20sl2UuEMIIAACn4LJMxyOMAABwEpdl7GjTdPDLli3ToEGDlJCQoJycHH344YdnXX/16tUaPny4EhISNGrUKL355pttKhYAgPbScDyg8sN1Kv7kkF7Ysk+LX9+l2/7rAx3y+jQsLVFvfP9qgkgHCXtk5OWXX9aiRYu0fPly5eTkaOnSpZo6darKysqUmpp62vqbN2/Wd77zHRUUFOjGG2/UypUrNWvWLG3fvl0jR45slz8CAIBvMsbocG2DKr46qs+/PqqKL4+q4qujJ98f04GaYzLm9O24LNPxXMac6X9Fy3JycnTllVfqV7/6lSQpEAgoMzNT3//+93Xfffedtv7s2bNVV1en9evXh5ZNmDBBY8aM0fLly1u1T4/Ho+TkZNXU1CgpKSmccgEADuUPGB1r9OtYw4nX0cbjTT83+EOfHW04rmONAR1rOC5P/XF9/vVR7f/qmCq+Oqpjjf6z7qNrXKwGpHRTZko3DUjppquHXqTJl6Z10F8Y/Vr7/R3WyEhDQ4O2bdumxYsXh5bFxMRoypQpKikpOeM2JSUlWrRoUbNlU6dO1dq1a1vcj8/nk8/nC733eDzhlNlq//VeuT7/+ugF+d0AcD7C+2diW35/yzswJ/dvZE7+N1jPyfcnPwuc8rNC651Y7g8YHQ8ETv7XnPiv/8SyU9/7A0aNwfVOvq8/fiJk+I4HzvvvdLmkvsldlZnSVZm9TgSOARc1hY+LusfL5XKd935wfsIKI4cPH5bf71daWvPUmJaWpo8//viM21RVVZ1x/aqqqhb3U1BQoIcffjic0trk9zsPaHvFkQu+HwBA27lcJ0YwusbFqmt8rLrFn/pzl2bLu8V3Uf9eXUOjHf16dlV8lza1R6IDReTdNIsXL242muLxeJSZmdnu+7llXH/lDrmo3X8vALQHl87vX+zn+gf/WT92ndi7y3WijhP/Pfn+5C8+42cn33eJcalLbIy6xLgUG+NSl1iXYmNiFHeO911iXHJ3iWkWNBLiYhi9iHJhhZHevXsrNjZW1dXVzZZXV1crPT39jNukp6eHtb4kud1uud3ucEprk9tyBl7wfQAAgLMLa+wqPj5e48aNU2FhYWhZIBBQYWGhcnNzz7hNbm5us/UlacOGDS2uDwAAOpewL9MsWrRIc+bM0RVXXKHx48dr6dKlqqur09y5cyVJeXl56tevnwoKCiRJCxYs0MSJE7VkyRJNnz5dq1at0tatW/XMM8+0718CAAAcKewwMnv2bB06dEgPPvigqqqqNGbMGL311luhJtWKigrFxDQNuFx11VVauXKl/vVf/1X333+/Lr74Yq1du5Y5RgAAgKQ2zDNiA/OMAADgPK39/uZ+JwAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGBV2NPB2xCcJNbj8ViuBAAAtFbwe/tck707Iox4vV5JUmZmpuVKAABAuLxer5KTk1v83BHPpgkEAjpw4IASExPlcrmafebxeJSZman9+/fz3JpW4pi1DcetbThubcNxCx/HrG0u5HEzxsjr9apv377NHqL7TY4YGYmJiVH//v3Puk5SUhInX5g4Zm3DcWsbjlvbcNzCxzFrmwt13M42IhJEAysAALCKMAIAAKxyfBhxu9166KGH5Ha7bZfiGByztuG4tQ3HrW04buHjmLVNJBw3RzSwAgCA6OX4kREAAOBshBEAAGAVYQQAAFhFGAEAAFY5OowsW7ZMgwYNUkJCgnJycvThhx/aLimi/fSnP5XL5Wr2Gj58uO2yIs6mTZs0Y8YM9e3bVy6XS2vXrm32uTFGDz74oDIyMtS1a1dNmTJFn376qZ1iI8i5jtvtt99+2vl3ww032Ck2QhQUFOjKK69UYmKiUlNTNWvWLJWVlTVbp76+Xvn5+brooovUo0cP3XLLLaqurrZUcWRozXGbNGnSaefb3Xffbali+55++mmNHj06NLFZbm6u/vCHP4Q+t32eOTaMvPzyy1q0aJEeeughbd++XdnZ2Zo6daoOHjxou7SIdtlll6mysjL0eu+992yXFHHq6uqUnZ2tZcuWnfHzxx9/XP/xH/+h5cuX64MPPlD37t01depU1dfXd3ClkeVcx02Sbrjhhmbn30svvdSBFUae4uJi5efna8uWLdqwYYMaGxt1/fXXq66uLrTOD37wA73xxhtavXq1iouLdeDAAd18880Wq7avNcdNkubNm9fsfHv88cctVWxf//799eijj2rbtm3aunWr/u7v/k4zZ87Unj17JEXAeWYcavz48SY/Pz/03u/3m759+5qCggKLVUW2hx56yGRnZ9suw1EkmTVr1oTeBwIBk56ebp544onQsiNHjhi3221eeuklCxVGpm8eN2OMmTNnjpk5c6aVepzi4MGDRpIpLi42xpw4t+Li4szq1atD6/zlL38xkkxJSYmtMiPON4+bMcZMnDjRLFiwwF5RDtCrVy/z7LPPRsR55siRkYaGBm3btk1TpkwJLYuJidGUKVNUUlJisbLI9+mnn6pv374aPHiwbrvtNlVUVNguyVHKy8tVVVXV7NxLTk5WTk4O514rFBUVKTU1VcOGDdM999yjL7/80nZJEaWmpkaSlJKSIknatm2bGhsbm51vw4cP14ABAzjfTvHN4xb04osvqnfv3ho5cqQWL16so0eP2igv4vj9fq1atUp1dXXKzc2NiPPMEQ/K+6bDhw/L7/crLS2t2fK0tDR9/PHHlqqKfDk5OVqxYoWGDRumyspKPfzww7rmmmu0e/duJSYm2i7PEaqqqiTpjOde8DOc2Q033KCbb75ZWVlZ+uyzz3T//fdr2rRpKikpUWxsrO3yrAsEAlq4cKGuvvpqjRw5UtKJ8y0+Pl49e/Zsti7nW5MzHTdJ+u53v6uBAweqb9++2rlzp/7lX/5FZWVlev311y1Wa9euXbuUm5ur+vp69ejRQ2vWrNGIESNUWlpq/TxzZBhB20ybNi308+jRo5WTk6OBAwfqlVde0R133GGxMnQG//iP/xj6edSoURo9erSGDBmioqIiTZ482WJlkSE/P1+7d++mjytMLR23u+66K/TzqFGjlJGRocmTJ+uzzz7TkCFDOrrMiDBs2DCVlpaqpqZGr776qubMmaPi4mLbZUlyaANr7969FRsbe1qnb3V1tdLT0y1V5Tw9e/bUJZdcor1799ouxTGC5xfn3vkbPHiwevfuzfknaf78+Vq/fr3effdd9e/fP7Q8PT1dDQ0NOnLkSLP1Od9OaOm4nUlOTo4kderzLT4+XkOHDtW4ceNUUFCg7Oxs/eIXv4iI88yRYSQ+Pl7jxo1TYWFhaFkgEFBhYaFyc3MtVuYstbW1+uyzz5SRkWG7FMfIyspSenp6s3PP4/Hogw8+4NwL0+eff64vv/yyU59/xhjNnz9fa9as0caNG5WVldXs83HjxikuLq7Z+VZWVqaKiopOfb6d67idSWlpqSR16vPtmwKBgHw+X2ScZx3SJnsBrFq1yrjdbrNixQrz0Ucfmbvuusv07NnTVFVV2S4tYt17772mqKjIlJeXm/fff99MmTLF9O7d2xw8eNB2aRHF6/WaHTt2mB07dhhJ5sknnzQ7duww+/btM8YY8+ijj5qePXuadevWmZ07d5qZM2earKwsc+zYMcuV23W24+b1es0Pf/hDU1JSYsrLy80777xjLr/8cnPxxReb+vp626Vbc88995jk5GRTVFRkKisrQ6+jR4+G1rn77rvNgAEDzMaNG83WrVtNbm6uyc3NtVi1fec6bnv37jWPPPKI2bp1qykvLzfr1q0zgwcPNtdee63lyu257777THFxsSkvLzc7d+409913n3G5XObtt982xtg/zxwbRowx5pe//KUZMGCAiY+PN+PHjzdbtmyxXVJEmz17tsnIyDDx8fGmX79+Zvbs2Wbv3r22y4o47777rpF02mvOnDnGmBO39z7wwAMmLS3NuN1uM3nyZFNWVma36AhwtuN29OhRc/3115s+ffqYuLg4M3DgQDNv3rxO/4+HMx0vSeb5558PrXPs2DHzve99z/Tq1ct069bN3HTTTaaystJe0RHgXMetoqLCXHvttSYlJcW43W4zdOhQ86Mf/cjU1NTYLdyif/7nfzYDBw408fHxpk+fPmby5MmhIGKM/fPMZYwxHTMGAwAAcDpH9owAAIDoQRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABg1f8HKG3uA8ka0CkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([a for a in range(1, len(losses) + 1)], losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4c11e-18ad-44fd-8f77-cf205932ee15",
   "metadata": {
    "id": "49c4c11e-18ad-44fd-8f77-cf205932ee15"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
