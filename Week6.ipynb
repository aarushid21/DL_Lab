{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d97b2-2acd-4319-b7ab-9c2b98df5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform classficiation on Fashion MNIST with the imported model from MNIST digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40d457c5-058c-46d7-af54-a6fa24b8bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from keras.datasets import mnist\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1, 64, kernel_size = 4), \n",
    "        nn.ReLU(), \n",
    "        nn.MaxPool2d((2, 2), stride = 2), \n",
    "        nn.Conv2d(64, 128, kernel_size = 3), \n",
    "        nn.ReLU(), \n",
    "        nn.MaxPool2d((2, 2), stride = 2), \n",
    "        nn.Conv2d(128, 64, kernel_size = 3), \n",
    "        nn.ReLU(), \n",
    "        nn.MaxPool2d((2, 2), stride = 2))\n",
    "        self.classification_head = nn.Sequential(nn.Linear(64, 20, bias = True),\n",
    "        nn.ReLU(), \n",
    "        nn.Linear(20, 10, bias = True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(1, -1))\n",
    "        \n",
    "class customdataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.y = self.y.type(torch.LongTensor)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def get_item(self, index):\n",
    "        return [self.x[index], self.y[index]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec0fa777-a458-4f16-b0f7-1b3e0bd297f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "State dictionary:\n",
      "net.0.weight \t torch.Size([64, 1, 4, 4])\n",
      "net.0.bias \t torch.Size([64])\n",
      "net.3.weight \t torch.Size([128, 64, 3, 3])\n",
      "net.3.bias \t torch.Size([128])\n",
      "net.6.weight \t torch.Size([64, 128, 3, 3])\n",
      "net.6.bias \t torch.Size([64])\n",
      "classification_head.0.weight \t torch.Size([20, 64])\n",
      "classification_head.0.bias \t torch.Size([20])\n",
      "classification_head.2.weight \t torch.Size([10, 20])\n",
      "classification_head.2.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "m2 = CNN()\n",
    "m2 = torch.load(\"m_modified.pt\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "m2.to(device)\n",
    "print(device)\n",
    "print(\"State dictionary:\")\n",
    "for param in m2.state_dict().keys():\n",
    "    print(param, \"\\t\", m2.state_dict()[param].size())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85171179-aa53-4613-b7f5-4f90a4621925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is  tensor(96.6300, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "m2.eval()\n",
    "correct = 0\n",
    "total = 0 \n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "data = customdataset(test_x, test_y)\n",
    "batch_size = 1\n",
    "test_loader = DataLoader(list(zip(data.x, data.y)), batch_size, shuffle = True)\n",
    "for i, vdata in enumerate(test_loader):\n",
    "    tinputs, tlabels = vdata\n",
    "    tinputs = tinputs.to(device)\n",
    "    tlabels = tlabels.to(device)\n",
    "    toutputs = m2(tinputs)\n",
    "    _, predicted = torch.max(toutputs, 1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted == tlabels).sum()\n",
    "accuracy = 100*correct/total\n",
    "print(\"The overall accuracy is \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c67998a3-207d-4e2b-b345-49d5f1249746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data entry: 0\n",
      "Data entry: 10000\n",
      "Data entry: 20000\n",
      "Data entry: 30000\n",
      "Data entry: 40000\n",
      "Data entry: 50000\n",
      "Data entry: 0\n",
      "Data entry: 10000\n",
      "Data entry: 20000\n",
      "Data entry: 30000\n",
      "Data entry: 40000\n",
      "Data entry: 50000\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torchvision import datasets, transforms \n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download = True, train= True, transform = transform)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(m2.parameters(), lr=0.01)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(2):\n",
    "    m2.train(True)\n",
    "    loss_t = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda() \n",
    "        optimizer.zero_grad()\n",
    "        outputs = m2.forward(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_t += loss.item()\n",
    "        if i%10000 == 0:\n",
    "            print(\"Data entry:\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5d6f2df-f2a5-46d6-87e7-d2cefb2eee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is  tensor(84.4300, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#test accuracy \n",
    "m2.eval()\n",
    "correct = 0\n",
    "total = 0 \n",
    "\n",
    "batch_size = 1\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download = True, train= False, transform = transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1)\n",
    "\n",
    "for i, vdata in enumerate(test_loader):\n",
    "    tinputs, tlabels = vdata\n",
    "    tinputs = tinputs.to(device)\n",
    "    tlabels = tlabels.to(device)\n",
    "    toutputs = m2(tinputs)\n",
    "    _, predicted = torch.max(toutputs, 1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted == tlabels).sum()\n",
    "accuracy = 100*correct/total\n",
    "print(\"The overall accuracy is \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d93a858-a90a-468e-9979-9c24c0749b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/student/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "#2. Learn the AlexNet architecture and apply transfer learning to perform the classification \n",
    "#task. Using the pre-trained AlexNet, classify images from the cats_and_dogs_filtered \n",
    "#dataset downloaded from the below link. Finetune the classifier given in Alexnet\n",
    "import PIL.Image\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import AlexNet_Weights \n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', model='alexnet',weights=AlexNet_Weights.DEFAULT)\n",
    "batch_size = 4\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a127601a-255d-4e01-aa7f-41f363d8b8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dogs', 'cats']\n",
      "No. of training examples for cats: 500\n",
      "No. of training examples for dogs: 500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = 'cats_and_dogs_filtered/validation/'\n",
    "classes = os.listdir(directory)\n",
    "cats = os.listdir(directory + \"/cats\")\n",
    "print(classes)\n",
    "print('No. of training examples for cats:', len(cats))\n",
    "dogs = os.listdir(directory + \"/dogs\")\n",
    "print('No. of training examples for dogs:', len(dogs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1be80367-fa10-4586-bab1-096422bdf8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is  tensor(45.0000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Resize((100,100)),transforms.ToTensor()])\n",
    "dataset = ImageFolder(directory, transform=transform)\n",
    "# print example\n",
    "# img, label = dataset[0]\n",
    "# print(img)\n",
    "# print(label)\n",
    "loader = DataLoader(dataset, batch_size)\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0 \n",
    "for i, vdata in enumerate(loader):\n",
    "    tinputs, tlabels = vdata\n",
    "    tinputs = tinputs.to(device)\n",
    "    tlabels = tlabels.to(device)\n",
    "    toutputs = model(tinputs)\n",
    "    _, predicted = torch.max(toutputs, 1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted == tlabels).sum()\n",
    "accuracy = 100*correct/total\n",
    "print(\"The overall accuracy is \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d050c53-d066-4007-ba68-6ba515e4df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Implement check points in PyTorch by saving model state_dict, optimizer state_dict, epochs\n",
    "#and loss during training so that the training can be resumed at a later point. Also, illustrate\n",
    "#the use of check point to save the best found parameters during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e4ddf51-2264-4d29-9a04-2979b0674110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "features.0.weight \t torch.Size([64, 3, 11, 11])\n",
      "features.0.bias \t torch.Size([64])\n",
      "features.3.weight \t torch.Size([192, 64, 5, 5])\n",
      "features.3.bias \t torch.Size([192])\n",
      "features.6.weight \t torch.Size([384, 192, 3, 3])\n",
      "features.6.bias \t torch.Size([384])\n",
      "features.8.weight \t torch.Size([256, 384, 3, 3])\n",
      "features.8.bias \t torch.Size([256])\n",
      "features.10.weight \t torch.Size([256, 256, 3, 3])\n",
      "features.10.bias \t torch.Size([256])\n",
      "classifier.1.weight \t torch.Size([4096, 9216])\n",
      "classifier.1.bias \t torch.Size([4096])\n",
      "classifier.4.weight \t torch.Size([4096, 4096])\n",
      "classifier.4.bias \t torch.Size([4096])\n",
      "classifier.6.weight \t torch.Size([2, 4096])\n",
      "classifier.6.bias \t torch.Size([2])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
     ]
    }
   ],
   "source": [
    "#training classifier section\n",
    "directory = 'cats_and_dogs_filtered/train/'\n",
    "transform = transforms.Compose([transforms.Resize((100,100)),transforms.ToTensor()])\n",
    "dataset = ImageFolder(directory, transform=transform)\n",
    "# print(len(dataset))\n",
    "train_loader = DataLoader(dataset, batch_size)\n",
    "device = 'cuda'\n",
    "optimizer = optim.SGD(m2.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97991908-0c74-4482-bbff-e0dbada2a6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 ] loss:470.59267880767584\n",
      "[ 1 ] loss:471.9527007192373\n",
      "[ 2 ] loss:469.7962705641985\n",
      "[ 3 ] loss:473.22094079852104\n",
      "[ 4 ] loss:470.1583635658026\n",
      "[ 5 ] loss:469.27484180033207\n",
      "[ 6 ] loss:468.8068710491061\n",
      "[ 7 ] loss:477.7873417586088\n",
      "[ 8 ] loss:469.6270612254739\n",
      "[ 9 ] loss:467.2623813673854\n"
     ]
    }
   ],
   "source": [
    "for feature in model.features:\n",
    "    feature.trainable = False\n",
    "model.compile()\n",
    "model.to('cpu')\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0\n",
    "    for i, vdata in enumerate(train_loader):\n",
    "        tinputs, tlabels = vdata\n",
    "        toutputs = model(tinputs)\n",
    "        loss = loss_fn(toutputs, tlabels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(\"[ \" + str(epoch) + \" ] loss:\" + str(running_loss))       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a0251b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': running_loss,\n",
    "            }, 'm1.pt')\n",
    "checkpoint = torch.load('m1.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
